\subsection{Paging}\label{subsec:Paging}
Most memory-management schemes used before the introduction of \nameref{def:Paging} suffered from the problem of fitting memory chunks of varying sizes on the \nameref{def:Backing_Store}
This arises because space must be found on the backing store, when main memory needs to be swapped out.
The backing store has the same \nameref{def:Fragmentation} problems discussed in connection with main memory, but access is much slower, so compaction is impossible.

\begin{definition}[Paging]\label{def:Paging}
  \emph{Paging} allows the \nameref{def:Physical_Address_Space} of a \nameref{def:Process} to be noncontiguous.
  This is achieved breaking up \nameref{def:Physical_Memory} and \nameref{def:Logical_Address_Space} into equally, fixed-size blocks.
  \begin{itemize}[noitemsep]
  \item \nameref{def:Physical_Memory} is broken up into \emph{frames}.
  \item \nameref{def:Logical_Address_Space} is broken up into \emph{pages}.
  \item The \nameref{def:Backing_Store} is also broken up, as a multiple (1 through $n$) of the frame size.
  \end{itemize}

  The list of pages and their mapping to frames for this \nameref{def:Process} is stored in the \nameref{def:Page_Table}.
  There is a page table in each process, which is used when this process \nameref{def:Context_Switch}es into the CPU.\@
  Therefore, paging also increases context switch time.

  Paging avoids the issue of \nameref{def:External_Fragmentation} and solves the problem of fitting memory chunks of varying sizes on the \nameref{def:Backing_Store}.
  However, \nameref{def:Internal_Fragmentation} is still an issue.
\end{definition}

\nameref{def:Paging} is implemented through cooperation between the operating system and the computer hardware.
Similar to how \nameref{def:Segmentation} has a segment table, \textbf{EACH \nameref{def:Process}} in a \nameref{def:Paging} system has a \nameref{def:Page_Table}.

\begin{definition}[Page Table]\label{def:Page_Table}
  A \emph{page table} is a table that maintains the mapping of logical pages to physical frames in memory.
  The page table is a simple lookup table, where the current \nameref{def:Process}'s current page number is also the value of the index.
  The value contained at that element is the location of the frame in memory.
  This is combined with the use of \nameref{def:Logical_Address}es that are generated by the CPU.\@
\end{definition}

To reach an address, the CPU generates a \nameref{def:Logical_Address} that has 2 parts, a page number $p$ and a page offset $d$.
Like before, the page number is used as an \textbf{INDEX} in the \nameref{def:Page_Table}.
The page table contains the base address of each page in physical memory.
This base address is combined with the page offset to define the physical memory address that is sent to the memory unit.

The frame size, and thus the page size, are defined by the hardware.
The size of a page is a power of 2, varying between 512 bytes and $\SI{1}{\gibi\byte}$\footnote{\si{\gibi\byte} is a gibibyte, or \si[prefixes-as-symbols=false]{\gibi} bytes} per page, depending on the computer architecture.
A power of 2 as a page size makes the translation of a \nameref{def:Logical_Address} into a page number and page offset particularly easy.

If the size of the logical address space is $2^{m}$, and a page size is $2^{n}$ bytes, then the high-order $m-n$ \textbf{bits} of a \nameref{def:Logical_Address} designate the page number, and the $n$ low-order \textbf{bits} designate the page offset.
\begin{equation}\label{eq:Page_Table_Calculations}
  \begin{aligned}
    p &= m-n \\
    d &= n \\
  \end{aligned}
\end{equation}

Thus, to translate the \nameref{def:Logical_Address} to a \nameref{def:Physical_Address}, \Cref{eq:Paging_Logical_Physical_Address_Conversion} is used.

\begin{equation}\label{eq:Paging_Logical_Physical_Address_Conversion}
  f = \bigl( i(p) \times s \bigr) + d
\end{equation}
\begin{description}[noitemsep]
\item $f$: Resulting \nameref{def:Physical_Address}.
\item $i(p)$: Mapped frame number of the given page number $p$ from the \nameref{def:Page_Table}.
\item $s$: Size of the page/frame.
\end{description}

If \nameref{def:Process} size is independent of page size, we expect \nameref{def:Internal_Fragmentation} to average one-half page per process.
This consideration suggests that small page sizes are desirable.
However, overhead is involved in maintaining the \nameref{def:Page_Table} itself, with each page-table entry increasing the overhead.
Also, disk I/O is more efficient when the amount data being transferred is larger.

Generally, page sizes have grown over time as processes, data sets, and main memory have become larger.
Today, pages typically are between $\SI{4}{\kibi{}\byte{}}$ and $\SI{8}{\kibi{}\byte{}}$ in size, and some systems support even larger page sizes.
Some CPUs and kernels now support multiple page sizes.
Variable on-the-fly page size is still being developed.

A 32-bit CPU uses 32-bit addresses, meaning that a given \nameref{def:Process}'s memory space can only be $2^{32}$ bytes ($\SI{4}{\gibi{}\byte{}}$).
However, a single 32-bit entry can point to one of $2^{32}$ different physical frames.
If frame size is 4 KB ($2^{12}$), then a system with 4-byte (32-bit) entries can address $2^{44}$ bytes (or $\SI{16}{\tebi{}\byte{}}$) of physical memory.
Therefore, paging lets us use physical memory that is larger than what can be addressed by the CPU’s address pointer length.
This means that the size of physical memory in a paged memory system is different from the maximum logical size of a process.

When a \nameref{def:Process} arrives in the system to be executed, its size, in pages, is examined.
Because pages and frames are the same size, if the process requires $n$ pages, at least $n$ frames must be available in memory.
If the required $n$ frames are available, they are allocated to this arriving process.
The first page of the process is loaded into one of the allocated frames, and the that frame's number is put in the \nameref{def:Page_Table} for this process for this page.
The next page is loaded into another frame, its frame number is put into the page table, and so on.

\nameref{def:Paging} offers a clear separation between the programmer’s view of memory and the actual hardware.
The logical addresses that the programmer uses are translated into physical addresses that the hardware uses.
This mapping is hidden from the programmer and is controlled by the operating system.
This allows the programmer to view memory as one contiguous space, containing only this one program (which helps create our definition of \nameref{def:Virtual_Memory}).
However, the user program may be scattered throughout \nameref{def:Physical_Memory}, which also holds other programs.
The difference between the programmer’s view of memory and the actual physical memory is reconciled by the address-translation hardware in the \nameref{def:Memory_Management_Unit}.

Because the \nameref{def:Operating_System} is managing \nameref{def:Physical_Memory}, it must be aware of the allocation details of physical memory, including:
\begin{itemize}[noitemsep]
\item Which frames are allocated.
\item Which frames are available.
\item The total number of frames.
\item etc.
\end{itemize}
This information is generally kept in a data structure called a \nameref{def:Frame_Table}.

\begin{definition}[Frame Table]\label{def:Frame_Table}
  The \emph{frame table} has one entry for each physical frame, indicating whether it is free or allocated and, if it is allocated, to which page of which process or processes.

  This behaves like an ownership or state table, rather than a lookup table.
  It says whether this frame is in use, and if it is, who is using it.
\end{definition}

\subsubsection{Hardware Support for Paging}\label{subsubsec:Paging_Hardware_Support}
Every access to memory must go through the paging map, so efficiency is a major consideration.
Each \nameref{def:Operating_System} has its own methods for storing \nameref{def:Page_Table}s.
Some allocate a page table for each \nameref{def:Process}, then a pointer to the page table is stored with the other register values in the \nameref{def:Process_Control_Block}.
Other operating systems provide only a few page tables, which decreases the overhead involved when processes are \nameref{def:Context_Switch}ed.

The hardware implementation of the \nameref{def:Page_Table} can be done in several ways.
In the simplest case, the page table is implemented as a set of high-speed, dedicated registers, making paging-address translation efficient.
The CPU \nameref{def:Dispatcher} reloads these registers, along with all the other registers.
Instructions to load or modify the page-table registers are privileged so that only the \nameref{def:Operating_System} can change the memory map.

Registers can be used for the \nameref{def:Page_Table} only if the page table is reasonably small.
However, modern computers, allow the page table to be quite large, making the use of registers to implement the page table not feasible.
Instead, the page table is kept in main memory, and a \texttt{page-table base register} (\texttt{PTBR}) points to the page table.
Thus, changing the currently active page table requires changing only this one register, substantially reducing \nameref{def:Context_Switch} time.
However, now this requires 2 memory access:
\begin{enumerate}[noitemsep]
\item Memory Access 1 is needed to enter the \nameref{def:Page_Table} and find the frame entry.
\item Memory Access 2 is needed to travel to \nameref{def:Physical_Memory} and retrieve the value.
\end{enumerate}

\paragraph{Translation Look-Aside Buffers}\label{par:Translation_Look_Aside_Buffers}
To accomodate the \nameref{def:Page_Table} existing in memory, a hardware cache is usually provided on the CPU, called a \emph{translation look-aside buffer} (\emph{TLB}).
The TLB is associative, high-speed memory that contains two part entries: a key and a value.
When the associative memory is presented an item, the item is compared with all keys \textbf{simultaneously}.
If the item is found, the corresponding value is returned.
This search is very fast.
In modern hardware, a TLB lookup is part of the instruction pipeline, essentially adding no performance penalty.
To be able to execute the search within a pipeline step, the TLB is small, typically between 32 and 1,024 \nameref{def:Page_Table} entries in size.

\begin{enumerate}[noitemsep]
\item When a \nameref{def:Logical_Address} is generated by the CPU, its page number is presented to the TLB.\@
\item These steps are executed as part of the instruction pipeline within the CPU, adding no performance penalty compared with a system that does not implement paging.
\item If the page number is found, its frame number is immediately available and is used to access memory.
\item If the page number is not in the TLB (a \emph{TLB miss}), a memory reference to the \nameref{def:Page_Table} must be made.
  \begin{itemize}[noitemsep]
  \item Depending on the CPU, this may be done automatically in hardware or via an \nameref{def:Interrupt} to the \nameref{def:Operating_System}.
  \item When the frame number is obtained, we can use it to access memory.
  \item In addition, the page number and frame number are added to the TLB, so that they will be found quickly on the next reference.
  \item If the TLB is already full of entries, an existing entry must be selected for replacement. Replacement policies vary.
    \begin{itemize}[noitemsep]
    \item Least Recently Used (LRU)
    \item Round-robin
    \item Random
    \end{itemize}
  \item Some CPUs allow the operating system to participate in LRU entry replacement, while others handle the matter themselves.
  \end{itemize}
\end{enumerate}

Some TLBs allow certain entries to be wired down, meaning that they cannot be removed from the TLB.\@
Typically, TLB entries for key kernel code are wired down.

TLBs are a hardware feature and the \nameref{def:Operating_System} designer needs to understand the function and features of \textbf{that} hardware platform's TLBs.
For optimal operation, \nameref{def:Paging} must be implemented according to the platform’s TLB design.
Likewise, a change in the TLB design may necessitate a change in the paging implementation of the operating systems that use it.

\paragraph{Address-Space Identifiers}\label{par:Address_Space_Identifiers}
Some TLBs store \emph{address-space identifier}s (\emph{ASID}s) in \textbf{each} TLB entry.
An ASID uniquely identifies each process and provides address-space protection for that process.
When the TLB attempts to resolve virtual page numbers, it ensures that the ASID for the currently running \nameref{def:Process} matches the ASID associated with the virtual page.
\textbf{If the ASIDs do not match}, the attempt is treated as a \textbf{TLB miss}.
ASIDs also allow the TLB to contain entries for several \textbf{different} processes simultaneously.
If the TLB does not support separate ASIDs, every time a new page table is selected (context switch), the TLB must be flushed (erased) to ensure that the next executing process does not use the wrong translation information.
Otherwise, the TLB could include old entries that contain valid virtual addresses but have incorrect or invalid physical addresses left over from the previous process.

\subsubsection{Memory Protection}\label{subsubsec:Paging_Memory_Protection}
The \nameref{def:User} \nameref{def:Process}, by definition, is unable to access memory it does not own.
The user process has no way of addressing memory outside of its \nameref{def:Page_Table}, since the page table includes \textbf{only} those pages that this process owns.
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../EDAF35-Operating_Systems-Reference_Sheet"
%%% End:
