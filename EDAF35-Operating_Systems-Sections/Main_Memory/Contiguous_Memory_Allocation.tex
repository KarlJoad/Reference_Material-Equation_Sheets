\subsection{Contiguous Memory Allocation}\label{subsec:Contiguous_Memory_Allocation}
Main memory must contain everything for the system to run, including both the \nameref{def:Operating_System} and \nameref{def:User} \nameref{def:Process}es.
It is our jobs, as operating system engineers to make the allocation of memory for the \nameref{def:Operating_System} as efficient as possible.
The earliest and simplest method is that of \nameref{def:Contiguous_Memory_Allocation}.

Memory is usually divided into two partitions: one for the \nameref{def:Operating_System} and one for the user processes.
We can place the operating system in either low memory or high memory, depending on the location of the \nameref{def:Interrupt_Vector}.
Typically, the interrupt vector is in low addresses, so the OS is usually put there too.
Throughout this document, we assume that the OS inhabits the lowest addresses.

\begin{definition}[Contiguous Memory Allocation]\label{def:Contiguous_Memory_Allocation}
  In \emph{contiguous memory allocation}, each \nameref{def:Process} is contained in a single contiguous section of memory that is also contiguous with the next process.

  In short, this means that each \nameref{def:Process} sits in its own contiguous block and is right next to the next process.
\end{definition}

\subsubsection{Memory Protection}\label{subsubsec:Contiguous_Memory_Protection}
In \nameref{def:Contiguous_Memory_Allocation}, we can provide memory protection by using concepts from earlier.
If the \texttt{base} register is considered as the \texttt{relocation} register (because of \nameref{def:Logical_Address} conversion to \nameref{def:Physical_Address}), and use the \texttt{limit} register as before, then we can protect this \nameref{def:Process}.
Since the \nameref{def:Operating_System} is the only entity that can change the values of the \texttt{relocation} and \texttt{limit} registers, this (currently executing) process and others cannot interfere with each other.

When the \nameref{rmk:CPU_Scheduler} selects a \nameref{def:Process} for execution, the \nameref{def:Dispatcher} loads the \texttt{relocation} and \texttt{limit} registers with the correct values as part of the \nameref{def:Context_Switch}.
Because every address generated by a CPU is checked against these registers, we can protect the operating system and other usersâ€™ programs and data from being modified by this running process.
This scheme is an effective way to allow the \nameref{def:Operating_System} to change size dynamically, which is highly desireable.

\subsubsection{Memory Allocation}\label{subsubsec:Contiguous_Memory_Allocation}
Within the \nameref{def:User} memory, there are 2 main methods of \nameref{def:Process}-memory allocation:
\begin{enumerate}[noitemsep]
\item \nameref{par:Multiple_Partition_Scheme}
\item \nameref{par:Variable_Partition_Scheme}
\end{enumerate}

Both methods use the same idea of dividing all free memory into separate partitions, however the size of these partitions and how they are divided is the differentiating factor.

\paragraph{Multiple-Partition Scheme}\label{par:Multiple_Partition_Scheme}
In the \emph{multiple-partition scheme}, all free memory is statically divided into equal sized partitions.
Thus, the size of a partition is fixed throughout the execution of the \nameref{def:Operating_System}.
When a partition is free, a \nameref{def:Process} is selected from the input queue and placed into the free partition.
When the process terminates, the partition is returned to the pool of available partitions.

\paragraph{Variable-Partition Scheme}\label{par:Variable_Partition_Scheme}
In the \emph{variable-partition scheme}, all free memory is pooled together.
The free memory is called a \emph{hole}.

\begin{blackbox}
  In many ways, this mirrors the use of the heap in programs.
  Many of the principles from heap and the allocation of stuff to the heap also apply in this case as well.
\end{blackbox}

As \nameref{def:Process}es are selected from the input queue to run, their memory requirements are considered.
The system searches the set for a hole that is large enough for this process.
If the hole is too large, it is split into two parts.
The process is then given an appropriate amount of space from memory, taken from the pool of free memory; the other is returned to the set of holes.
When a process terminates, it releases its block of memory, which is then placed back in the set of holes.
If the new hole is adjacent to other holes, these adjacent holes are merged to form one larger hole.

At this point, the system may need to check whether there are processes waiting for memory and whether this newly freed and recombined memory could satisfy the demands of any of these waiting processes.
The next process to run has its memory requirements considered, \textbf{AND} the free memory available.
What happens next depending on the \nameref{def:Operating_System}:
\begin{itemize}[noitemsep]
\item Wait until a large enough block of memory is available for this process.
\item Skip through the input queue to find a process that can use the memory (because of smaller requirements).
\end{itemize}

Just like in heap allocation and garbage collection, this is a particular instance of the general dynamic storage-allocation problem.
In \nameref{def:Operating_System}s, there are 3 common strategies used to allocate this memory to \nameref{def:Process}es:
\begin{enumerate}[noitemsep]
\item \nameref{subpar:First_Fit}
\item \nameref{subpar:Best_Fit}
\item \nameref{subpar:Worst_Fit}
\end{enumerate}

\subparagraph{First-Fit}\label{subpar:First_Fit}
\subparagraph{Best-Fit}\label{subpar:Best_Fit}
\subparagraph{Worst-Fit}\label{subpar:Worst_Fit}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../EDAF35-Operating_Systems-Reference_Sheet"
%%% End:
