\subsection{Implicit Threading}\label{subsec:Implicit_Threading}
Because programs are starting to use so many \nameref{def:Thread}s that it is becoming hard to manage, the creation and management of threads is moving from developers to compilers/run-time libaries.
This way, the computer manages threads rather than the programmer.

\begin{definition}[Implicit Threading]\label{def:Implicit_Threading}
  \emph{Implicit Threading} is the transfer of \nameref{def:Thread} creation and management away from the programmer, and to the compiler and/or run-time libaries.
  This frees the programmer from having to think/worry about the issues that arise because of multithreading, while still allowing programs to take advantage of the benefits of multithreading.
\end{definition}

There exist 3 main methods for implementing implicit threading:
\begin{enumerate}[noitemsep]
\item \nameref{subsubsec:Thread_Pools}
\item \nameref{subsubsec:OpenMP}
\item \nameref{subsubsec:Grand_Central_Dispatch}
\end{enumerate}

\subsubsection{Thread Pools}\label{subsubsec:Thread_Pools}
In a \nameref{def:Thread_Pool} system, all (or at least most) of the \nameref{def:Thread}s available for use by a \nameref{def:Process} are created during startup.
They are then placed in a pool, and wait for work to arrive.

\begin{definition}[Thread Pool]\label{def:Thread_Pool}
  A \emph{thread pool} system is one where all \nameref{def:Thread}s that can be used by any \nameref{def:Process} on the system is in a pool, hence the name.
  When a job comes in that would use one (or more) of these threads, they are pulled out of the pool and allowed to execute.
  When they finish execution, they return to the pool.

  If there are jobs ready, but there are no threads available in the pool, they wait until one is available.
\end{definition}

A \nameref{def:Thread_Pool} offers these benefits:
\begin{enumerate}[noitemsep]
\item Servicing a request with an \textbf{existing thread} is faster than waiting \textbf{to create a thread}.
\item A thread pool limits the number of threads that exist at any one point, preventing performance degradation.
  This is particularly important on systems that cannot support a large number of concurrent threads.
\item Separating the task to be performed from the mechanics of creating the task allows us to use different strategies for running the task.
\end{enumerate}

Additionally, the number of \nameref{def:Thread}s available in the \nameref{def:Thread_Pool} can be set dynamically.
Some factors that can affect the number of threads in the pool are:
\begin{enumerate}[noitemsep]
\item Number of CPUs in the system
\item Amount of physical memory
\item Expected number of concurrent job requests
\end{enumerate}

There are more sophisticated architectures that offer varying benefits.
Some even allow for the shrinking of the pool as needed, to reduce the footprint of the running \nameref{def:Process}.

\subsubsection{OpenMP}\label{subsubsec:OpenMP}
OpenMP is a set of compiler directives as well as an API for programs written in C, C++, or FORTRAN that provides support for parallel programming in shared-memory environments.
OpenMP allows for parallel programming by identifying parallel regions as blocks of code that may run in parallel.
Application developers insert compiler directives into their code at parallel regions they know can be executed in parallel, and these directives instruct the OpenMP runtime library to execute the region in parallel.

It can create as many threads as are available in a system with the \kernelinline{#pragma omp parallel} directive.
There are also directives for parallelizing loops, automatically dividing the work among the spawned threads.

\subsubsection{Grand Central Dispatch}\label{subsubsec:Grand_Central_Dispatch}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../EDAF35-Operating_Systems-Reference_Sheet"
%%% End:
