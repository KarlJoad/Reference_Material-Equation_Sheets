\subsection{Other Topics to Consider}\label{subsec:Other_Topics_to_Consider}
Here, we mention considerations, other than a \nameref{def:Page_Replacement} algorithm and frame allocation policy to choosing how to create our \nameref{def:Paging} system.

\subsubsection{Prepaging}\label{subsubsec:Prepaging}
An obvious property of pure \nameref{def:Demand_Paging} is the large number of \nameref{def:Page_Fault}s that occur when a \nameref{def:Process} is started or when a swapped out process is restarted.
This situation results from trying to get the initially executing locality into memory.
\nameref{def:Prepaging} helps ease this situation.

\begin{definition}[Prepaging]\label{def:Prepaging}
  \emph{Prepaging} is an attempt to prevent this high level of initial paging.
  The strategy is to bring into all the pages that will be needed into memory at one time.
\end{definition}

In a system using the \nameref{subsubsec:Working_Set_Model}, for example, we could keep with each \nameref{def:Process} a list of the pages in its working set.
If we must suspend a process, we remember the working set for that process.
When the process is to be resumed, we automatically bring back into memory its \textbf{entire working set} before restarting the process.

\nameref{def:Prepaging} may offer an advantage in some cases.
The question is whether the cost of using prepaging is less than the cost of servicing the corresponding page faults.
Prepaging becomes less effective if many of the pages brought back into memory by prepaging will not be used.

\subsubsection{Page Size}\label{subsubsec:Page_Size}
The designers of an \nameref{def:Operating_System} for an existing machine rarely have a choice concerning the page size.
However, a new machine can have different page sizes than its predecessors.
There is no single best page size.
Page sizes are almost always powers of 2, generally ranging from \SIrange{4096}{4194304}{\byte{}} ($2^{12}$ to $2^{22}$ byte, \SI{4}{\kibi{} \byte{}} to \SI{4}{\mebi{} \byte{}}).

How do we select a page size?
\begin{itemize}[noitemsep]
\item One concern is the size of the page table.
  \begin{itemize}[noitemsep]
  \item For a given virtual memory space, decreasing the page size increases the number of pages and hence the size of the page table.
  \end{itemize}

\item Because each active process must have its own copy of the \nameref{def:Page_Table}, a large page size is desirable.

\item Memory is better utilized with smaller pages.
  \begin{itemize}[noitemsep]
  \item To minimize \nameref{def:Internal_Fragmentation}, we need a small page size.
  \end{itemize}

\item Time required to read or write a page.
  Minimization of I/O time argues for a larger page size.
  \begin{itemize}[noitemsep]
  \item I/O time is composed of seek, latency, and transfer times.
    Transfer time is proportional to the amount transferred, meaning a small page size.
  \item Latency and seek time normally dwarf transfer time.
  \end{itemize}

\item With a smaller page size, total I/O should be reduced, since locality will be improved.
  \begin{itemize}[noitemsep]
  \item A smaller page size allows each page to match program locality more accurately.
\end{itemize}

\item With a smaller page size, then, we have better resolution, allowing us to isolate only the memory that is actually needed.
  \begin{itemize}[noitemsep]
  \item With a larger page size, we must allocate and transfer not only what is needed but also anything else that happens to be in the page, whether it is needed or not.
  \item Thus, a smaller page size should result in less I/O and less total allocated memory.
\end{itemize}
\item To minimize the number of page faults, we need to have a large page size.

\item What is the relationship between page size and sector size on the paging device?
\end{itemize}

This problem has no best answer.
As we have seen, some factors (\nameref{def:Internal_Fragmentation}, locality) argue for a small page size, whereas others (table size, I/O time) argue for a large page size.
The historical trend is toward larger page sizes.

\subsubsection{TLB Reach}\label{subsubsec:TLB_Reach}
Recall that the hit ratio for the Translation Lookaside Buffer (\texttt{TLB}) refers to the percentage of virtual address translations that are resolved in the TLB rather than the page table.
Clearly, the hit ratio is related to the number of entries in the TLB, and the way to increase the hit ratio is by increasing the number of entries in the TLB.\@
However, the associative memory used to construct the TLB is both expensive and power hungry.
Related to the hit ratio is another metric: the \nameref{def:TLB_Reach}.

\begin{definition}[TLB Reach]\label{def:TLB_Reach}
  \emph{TLB reach} refers to the amount of memory accessible from the Translation Lookaside Buffer (TLB).
  It is the number of entries multiplied by the page size.
\end{definition}

Ideally, the working set for a \nameref{def:Process} is stored in the TLB.\@
If it is not, the process will spend a considerable amount of time resolving memory references in the \nameref{def:Page_Table} rather than the TLB.\@

There are 3 methods to increase the \nameref{def:TLB_Reach}:
\begin{enumerate}[noitemsep]
\item Increase the number of entries in the TLB.\@

\item Increase the size of a page.
  \begin{itemize}[noitemsep]
  \item For example, increase the page size from \SI{8}{\kibi{} \byte{}} to \SI{32}{\kibi{} \byte{}}, quadruple the \nameref{def:TLB_Reach}.
  \item However, may to an increase in \nameref{def:Fragmentation}.
  \end{itemize}

\item Provide multiple page sizes.
  \begin{itemize}[noitemsep]
  \item Providing support for multiple page sizes requires the operating system
    —not hardware —to manage the TLB.\@
  \item One of the fields in a TLB entry must indicate the size of the page frame corresponding to the TLB entry.
  \item Managing the TLB in software and not hardware comes at a cost in performance.
  \item The increased hit ratio and TLB reach offset the performance costs.
  \item Recent trends indicate a move toward software-managed TLBs and operating-system support for multiple page sizes.
  \end{itemize}
\end{enumerate}

\subsubsection{Inverted Page Tables}\label{subsubsec:Inverted_Page_Tables}
The purpose of this form of page management is to reduce the amount of \nameref{def:Physical_Memory} needed to track virtual-to-physical address translations, by keeping information about which \nameref{def:Virtual_Memory} page is stored in each physical frame.
We accomplish this savings by creating a table that has one entry per page of physical memory, indexed by the pair $\langle \mathtt{PID}, page-number \rangle$.
However, the inverted page table no longer contains complete information about the \nameref{def:Logical_Address_Space} of a \nameref{def:Process}, and that information is required if a referenced page is not currently in memory.

\nameref{def:Demand_Paging} requires this information to process \nameref{def:Page_Fault}s.
For the information to be available, an external page table (one per \nameref{def:Process}) must be kept.
This table looks like the traditional per-process page table and contains information on where each virtual page is located.

Since these tables are referenced only when a \nameref{def:Page_Fault} occurs, they do not need to be available quickly.
Instead, they are themselves paged in and out of memory as necessary.
But now a page fault may cause the virtual memory manager to generate another page fault as it pages in the external page table it needs to locate the virtual page on the \nameref{def:Backing_Store}.
This special case requires careful handling in the \nameref{def:Kernel} and a delay in the page-lookup processing.

\subsubsection{Program Structure}\label{subsubsec:Program_Structure}
\nameref{def:Demand_Paging} is designed to be transparent to the \nameref{def:User} \nameref{def:Program}.
In many cases, the user is completely unaware of the paged nature of memory.
However, system performance can be improved if the user (or compiler) has an awareness of the underlying demand paging.

Good selection of data structures and programming structures can increase locality and hence lower the \nameref{def:Page_Fault} rate and the number of pages in the working set.
\begin{itemize}[noitemsep]
\item A stack has good locality, since access is always made to the top.
\item A hash table is designed to scatter references, producing bad locality.
\end{itemize}

Of course, locality of reference is just one measure of the efficiency of the use of a data structure.
Other heavily weighted factors include search speed, total number of memory references, and total number of pages touched.

At a later stage, the compiler and loader can have a significant effect on \nameref{def:Paging}.
Separating code and data and generating \nameref{def:Reentrant} code means that code pages can be read-only and hence will never be modified meaning they never have to be paged out to be replaced.
The loader can avoid placing routines across page boundaries, keeping each routine completely in one page.
Routines that call each other many times can be packed into the same page.
This packaging is a variant of the bin-packing problem: try to pack the variable-sized load segments into the fixed-sized pages so that interpage references are minimized.
This is particularly useful for large page sizes.

\subsubsection{I/O Interlock and Page Locking}\label{IO:subsubsec_Interlock_Page_Locking}
When using I/O devices with \nameref{def:Demand_Paging}, we sometimes need to allow some of the pages to be locked in memory.

One solution is never to execute I/O to \nameref{def:User} memory.
Instead, data is copied between \nameref{def:Kernel} memory and user memory, then the I/O takes place only between kernel memory and the I/O device.
To write a block on tape, we first copy the block to system memory and then write it to tape.
This extra copying may result in unacceptably high overhead.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../EDAF35-Operating_Systems-Reference_Sheet"
%%% End:
