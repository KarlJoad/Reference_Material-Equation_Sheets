\subsection{Page Replacement}\label{subsec:Page_Replacement}
If a \nameref{def:Process} of ten pages actually uses only half of them, then \nameref{def:Demand_Paging} saves the I/O necessary to load the five pages that are never used.
This also increases the degree of multiprogramming by running more processes, \nameref{def:Over_Allocating} memory.

\begin{definition}[Over-Allocating]\label{def:Over_Allocating}
  \emph{Over-allocating} is the process of putting more load on a component in the system than would normally be possible.

  In the context of \nameref{def:Paging} and \nameref{def:Demand_Paging}, this means that main memory has more \nameref{def:Process}es in it than would be normal in normal \nameref{def:Paging} schemes.
  This is because \textbf{ONLY} the pages that are needed to run these processes are loaded, and nothing more.
\end{definition}

If we run multiple \nameref{def:Process}es, each of which is multiple pages in size but actually only uses some of them, we can achieve higher CPU utilization and throughput, with physical frames to spare.
It is possible that each of these processes, for some reason, may suddenly try to use \textbf{all} of their pages \textbf{simulataneously}, resulting in a need for more physical frames than the system has.
The operating system has several options at this point:
\begin{enumerate}[noitemsep]
\item Terminate a user process.
  \begin{itemize}[noitemsep]
  \item \nameref{def:Demand_Paging} is the operating system’s attempt to improve the system’s utilization and throughput.
  \item Users should not be aware that their processes are running on a paged system—
  \item Paging should be logically transparent to the user.
  \item Not the best choice.
  \end{itemize}

\item Replace one page in memory with the requested one in swap (\nameref{def:Page_Replacement}).
  \begin{itemize}[noitemsep]
  \item \nameref{def:Operating_System} swaps out a process, freeing \textbf{all} its frames.
  \item Reduce the level of multiprogramming.
  \item Good option in certain circumstances (\nameref{def:Thrashing}).
  \end{itemize}
\end{enumerate}

\begin{definition}[Page Replacement]\label{def:Page_Replacement}
  \emph{Page replacement} is the process of replacing a page in memory with one that is \nameref{def:Swapping} in from the swap.

  Page replacement is basic to \nameref{def:Demand_Paging}.
  It completes the separation between logical memory and \nameref{def:Physical_Memory}.
  With this mechanism, an enormous \nameref{def:Virtual_Memory} can be provided for programmers on a smaller physical memory.
  Without demand paging, user addresses are still mapped into physical addresses, and the two sets of addresses can be different, however, all the pages of a process still must be in physical memory.
  With demand paging, the size of the \nameref{def:Logical_Address_Space} is no longer constrained by physical memory.

  The procedure for performing this replacement is listed in \Cref{subsubsec:Page_Replacement_Procedure}.
\end{definition}

Buffers for I/O also consume a considerable amount of memory.
Deciding how much memory to allocate to I/O and how much to program pages is a significant challenge.
Some systems allocate a fixed percentage of memory for I/O buffers, others allow user processes and the I/O subsystem to compete for all system memory.

\subsubsection{Replacement Procedure}\label{subsubsec:Page_Replacement_Procedure}
The basic steps to perform a \nameref{def:Page_Replacement} are shown below:
\begin{enumerate}[noitemsep]
\item Find the location of the desired page on the disk.
\item Find a free frame:
  \begin{enumerate}[noitemsep]
  \item If there is a free frame, use it.
  \item If there is no free frame, use a page-replacement algorithm to select a victim frame.
  \item Write the victim frame to the disk; change the page and frame tables accordingly.
  \end{enumerate}
\item Read the desired page into the newly freed frame; change the page and frame tables.
\item Continue the user process from where the page fault occurred.
\end{enumerate}

If no frames in memory are free, two page transfers (move one page out and one in) are required, effectively doubling the \nameref{def:Page_Fault} service time and increases the \nameref{def:Effective_Access_Time} accordingly.
Reducing this overhead can be done by using a \nameref{def:Modify_Bit} (\nameref{rmk:Dirty_Bit}).

\begin{definition}[Modify Bit]\label{def:Modify_Bit}
  The \emph{modify bit} is a signalling bit associated with each page or frame has a modify bit associated with it in the hardware.
  The modify bit for a page is set by the hardware whenever any byte in the page is written, indicating that the page has been modified.

  \begin{remark}[Dirty Bit]\label{rmk:Dirty_Bit}
    The \nameref{def:Modify_Bit} is sometimes called the \emph{dirty bit}, because if it is set, then the memory can be considered ``dirty'' and must be written before any further changes are made.
  \end{remark}
\end{definition}

When we select a page for replacement, we examine its \nameref{def:Modify_Bit}.
\begin{itemize}[noitemsep]
\item Modify Bit set, we know the page has been modified since the \textbf{last} read-in from the disk.
  \begin{itemize}[noitemsep]
  \item Must write the page to the disk.
  \end{itemize}
\item Modify Bit not set, the page \textbf{has not been modified} since it was read into memory.
  \begin{itemize}[noitemsep]
  \item No need to write the memory page to the disk; an exact replica is already there.
  \end{itemize}
\end{itemize}

\begin{remark*}
  This also applies to read-only pages (for example, pages of binary code).
  Since such pages cannot be modified, they may be discarded when desired.
  This can significantly reduce the time required to service a page fault, since it reduces \textbf{I/O time} by one-half if the page has not been modified.
\end{remark*}

\subsubsection{Algorithms}\label{subsubsec:Page_Replacement_Algorithms}
In general, we select a particular replacement algorithm with the lowest \nameref{def:Page_Fault} rate.
We evaluate an algorithm by running it on a particular string of memory references, called a reference string, and computing the number of page faults.

To determine the number of \nameref{def:Page_Fault}s for a particular reference string and \nameref{def:Page_Replacement} algorithm, we also need to know the number of frames available.
Obviously, as the number of frames available increases, the number of page faults decreases.
Adding physical memory increases the number of frames.
Between the number of frames and the number of page faults, we generally expect a negative-exponential curve.

\paragraph{FIFO Page Replacement}\label{par:FIFO_Page_Replacement}
The simplest page-replacement algorithm is a first-in, first-out algorithm.
A FIFO replacement algorithm associates with each page the time when that page was brought into memory.
When a page must be replaced, the oldest page is chosen.

It is not really necessary to record the time when a page is brought in.
Instead, we can use a FIFO queue to hold all pages in memory.
When a page is brought into memory, we insert it at the tail of the queue.
When a page is replaced, we replace the page at the head of the queue.

Notice that, even if we select a page that is being actively used for replacement, everything still works correctly.
After we replace the active page with a new one, a \nameref{def:Page_Fault} will occur almost immediately to retrieve the active page from the swap.
Then, some other page must be replaced to bring the active page back into memory.
Thus, a bad replacement choice increases the page-fault rate and slows process execution, but does not cause incorrect execution.

The FIFO \nameref{def:Page_Replacement} algorithm is easy to understand and program.
However, its performance is not always good.
Sometimes, the number of faults for more frames is greater than the number of faults for fewer frames.
This unexpected result is known as \nameref{def:Beladys_Anomaly}.

\begin{definition}[Belady's Anomaly]\label{def:Beladys_Anomaly}
  \emph{Belady's Anomaly} states that if the number of available frames to hold pages increases, the number of \nameref{def:Page_Fault}s will increase.
\end{definition}

\paragraph{Optimal Page Replacement}\label{par:Optimal_Page_Replacement}
A result of the discovery of \nameref{def:Beladys_Anomaly} was the search for an optimal \nameref{def:Page_Replacement} algorithm.
This is the algorithm with the lowest \nameref{def:Page_Fault} rate of all algorithms and will never suffer from Belady's Anomaly.
It was found and is called \nameref{def:Optimal_Page_Replacement_Algorithm}.

\begin{definition}[OPT Algorithm]\label{def:Optimal_Page_Replacement_Algorithm}
  The \emph{OPT} or \emph{MIN} \nameref{def:Page_Replacement} \emph{Algorithm} is that has the lowest \nameref{def:Page_Fault} rate of any and all algorithm, and never suffers fro \nameref{def:Beladys_Anomaly}.
  It is:
  \begin{center}
    Replace the page that will not be used for the longest period of time.
  \end{center}

  Use of this \nameref{def:Page_Replacement} algorithm guarantees the lowest possible \nameref{def:Page_Fault} rate for a fixed number of frames.
\end{definition}

Unfortunately, the optimal page-replacement algorithm is difficult, if not impossible, to implement, because it requires \textbf{future} knowledge of the reference string.
This is a similar situation as with the \nameref{par:SJF_Scheduling} algorithm in \Cref{par:SJF_Scheduling}.
As a result, the optimal algorithm is used mainly for comparison studies.
For instance, a new algorithm may not be optimal, but it is within \SI{12.3}{\percent} of optimal at worst and within \SI{4.7}{\percent} on average.

\paragraph{Least-Recently-Used (LRU) Page Replacement}\label{par:LRU_Page_Replacement}
If the \nameref{def:Optimal_Page_Replacement_Algorithm} is not feasible, perhaps an approximation of it is possible.
If we assume the recent past as an approximation of the near future, then we can replace the page that has not been used for the longest period of time.
This approach is the \nameref{def:LRU_Algorithm}.

\begin{definition}[Least Recently Used Algorithm]\label{def:LRU_Algorithm}
  The \emph{Least Recently Used} (\emph{LRU}) \emph{Algorithm} assumes that the past is a good approximation of the near future.
  This allows it to replace the page that has not been used for the longest time first, because it is unlikely that the page will be used.

  Like the \nameref{def:Optimal_Page_Replacement_Algorithm}, LRU replacement does not suffer from \nameref{def:Beladys_Anomaly}.
  Both belong to a class of \nameref{def:Page_Replacement} algorithms, called \nameref{def:Stack_Algorithm}s, that can never exhibit Belady’s anomaly.

  \begin{remark}[OPT and LRU Algorithm Performance]
    Let $S_{R}$ be the reverse of a reference string $S$.
    The \nameref{def:Page_Fault} rate for the \nameref{def:Optimal_Page_Replacement_Algorithm} on $S$ is the same as the page-fault rate for the OPT algorithm on $S_{R}$.
    Likewise, the page-fault rate for the LRU algorithm on $S$ is the same as the page-fault rate for the LRU algorithm on $S_{R}$.
  \end{remark}
\end{definition}

The \nameref{def:LRU_Algorithm} is often used as a \nameref{def:Page_Replacement} algorithm and is considered to be good.
The major problem is how to implement it.
The LRU page-replacement algorithm may require substantial hardware assistance to determine an order for the frames defined by the time of last use.
There are two reasonably feasible implementations:
\begin{enumerate}[noitemsep]
\item \textbf{Counters}.
  In this case, we associate with each \nameref{def:Page_Table} entry a Time-of-Use field and add to the CPU a logical clock or counter which is incremented for \textbf{every} memory reference.
  Whenever a reference to a page is made, the contents of the clock register are copied to the Time-of-Use field in the page-table entry for that page.
  This way, we always have the ``time'' of the last reference to each page.
  We replace the page with the smallest time value.
  \begin{itemize}[noitemsep]
  \item This scheme requires a search of the page table to find the LRU page and a write to memory (to the time-of-use field in the page table) for each memory access.
  \item The times must also be maintained when page tables are changed (due to CPU scheduling).
  \item Overflow of the clock must be considered.
  \end{itemize}

\item \textbf{Stack}.
  Another approach to implementing LRU replacement is to keep a stack of page numbers.
  Whenever a page is referenced, it is put on the top.
  In this way, the most recently used page is always at the top of the stack and the least recently used page is always at the bottom.
  Because entries must be removed from the middle of the stack, it is best to implement this approach by using a doubly linked list with a head pointer and a tail pointer.
  \begin{itemize}[noitemsep]
  \item Removing a page and putting it on the top of the stack then requires changing six pointers at worst.
  \item Each update is a little more expensive, but there is no search for a replacement.
    The tail pointer points to the bottom of the stack, the LRU page.
  \item This approach is particularly appropriate for software or microcode implementations of LRU replacement.
  \end{itemize}
\end{enumerate}

Both implementations of the \nameref{def:LRU_Algorithm} need additional hardware assistance beyond the standard TLB registers.
For example, updating the clock fields or stack must be done for every memory reference.
If we were to use an interrupt allowing software to update these data structures, it would signficantly slow every memory reference.

\begin{definition}[Stack Algorithm]\label{def:Stack_Algorithm}
  A \emph{stack algorithm} is an algorithm for which it can be shown that the set of pages in memory for $n$ frames is always a \textbf{subset} of the set of pages that would be in memory with $n+1$ frames.

  For the \nameref{def:LRU_Algorithm}, the set of pages in memory would be the $n$ most recently referenced pages.
  If the number of frames is increased, the same $n$ pages will still be the most recently referenced and will still be in memory.
\end{definition}

\paragraph{LRU-Approximation Page Replacement}\label{par:LRU_Approximation_Page_Replacement}
Few computer systems provide sufficient hardware support for true LRU page replacement.
Many provide some support, in the form of a \nameref{def:Reference_Bit}.

\begin{definition}[Reference Bit]\label{def:Reference_Bit}
  A \emph{Reference bit} is another bit that is associated with each entry in the \nameref{def:Page_Table}.
  The reference bit for a page is set by the hardware whenever that page is referenced (either a read or a write to any byte in the page).
\end{definition}

Initially, all bits are cleared by the \nameref{def:Operating_System}.
As a user \nameref{def:Process} executes, the \nameref{def:Reference_Bit} associated with each page is set by the hardware.
After some time, we can determine \textbf{which} pages have been used by examining the reference bits, although \textbf{we do not know the order of use}.
This information is the basis for many \nameref{def:Page_Replacement} algorithms that approximate \nameref{par:LRU_Page_Replacement}.

\end{itemize}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../EDAF35-Operating_Systems-Reference_Sheet"
%%% End:
