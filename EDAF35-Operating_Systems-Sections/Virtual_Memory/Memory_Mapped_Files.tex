\subsection{Memory-Mapped Files}\label{subsec:Memory_Mapped_Files}
The sequential read of a \nameref{def:File} on disk using the standard \nameref{def:System_Call}s \kernelinline{open()}, \kernelinline{read()}, and \kernelinline{write()}.
Each file access requires a system call and disk access.
To alleviate the pain of this, we could use \nameref{def:Memory_Mapping}.

\begin{definition}[Memory Mapping]\label{def:Memory_Mapping}
  \emph{Memory mapping} is the process of taking something and mapping it to a page in memory.
  This allows a page (possibly multiple) in the \nameref{def:Virtual_Address_Space} to be logically associated with a page-sized amount of something.
\end{definition}

\subsubsection{Basic Mechanism}\label{subsubsec:Basic_Memory_Mapping_Mechanism}
Memory mapping a file is accomplished by mapping a disk block to a page (or
pages) in memory.
The steps involved are:
\begin{enumerate}[noitemsep]
\item Initial access to the \nameref{def:File} proceeds through ordinary \nameref{def:Demand_Paging}, resulting in a \nameref{def:Page_Fault}.
\item A page-sized portion of the file is read from the file system into a physical frame.
  \begin{itemize}[noitemsep]
  \item Some systems may read in more than a page-sized chunk of memory at a time
  \end{itemize}
\item Subsequent reads and writes to the file (within the loaded paged-size amount of the file) are handled as routine memory accesses.
\end{enumerate}

\subsubsection{Benefits of Memory Mapping}\label{subsubsec:Memory_Mapping_Benefits}
Manipulating \nameref{def:File}s through memory rather than incurring the overhead of using the \kernelinline{read()} and \kernelinline{write()} system calls simplifies and speeds up file access and usage.

Multiple \nameref{def:Process}es may be allowed to map the same \nameref{def:File} concurrently, to allow sharing of data.
Writes by any of the processes modify the file's data in \nameref{def:Virtual_Memory} which can be seen by all others that map the same section of the file.
The \nameref{def:Memory_Mapping} \nameref{def:System_Call}s can also support \nameref{def:Memory_Copy_on_Write} functionality.
This allows processeses to share a file in read-only mode but to have their own copies of any data they modify.
to coordinate access to the shared data, the processes involved will use one of the mechanisms for achieving \nameref{def:Mutex}-like behavior.

\subsubsection{Caveats of Memory Mapping}\label{subsubsec:Memory_Mapping_Caveats}
Writes to the \nameref{def:File} mapped in memory are not necessarily immediate (synchronous) writes to the file on disk.
Some systems may choose to update the physical file when the operating system periodically checks whether the page in memory has been modified.
When the file is closed, all the data is written back to disk and removed from the \nameref{def:Virtual_Memory} of the \nameref{def:Process}.

\subsubsection{Memory Mapped I/O}\label{subsubsec:Memory_Mapped_IO}
Each I/O controller includes registers to hold commands and the data being transferred.
Usually, special I/O instructions allow data transfers between these registers and system memory.
For more convenient access to I/O devices, many computer architectures provide memory-mapped I/O.

\begin{definition}[Memory-Mapped I/O]\label{def:Memory_Mapped_IO}
  \emph{Memory-Mapped I/O} assigns ranges of memory addresses that map to the I/O device's registers.
  Reads and writes to these memory addresses cause the data to be transferred to and from the device registers automatically.
  This is appropriate for devices that have fast response times, such as video controllers.

  Memory-mapped I/O is also convenient for other devices, such as the serial and parallel ports.
  The CPU transfers data through these kinds of devices by reading and writing a few device registers, called an I/O port.
\end{definition}

To send out a long string of bytes through a memory-mapped \textbf{serial} port, the CPU writes one data byte to the data register and sets a bit in the control register to signal that the byte is available.
The device takes the data byte and then clears the bit in the control register to signal that it is ready for the next byte.
Then the CPU can transfer the next byte.
There are 2 ways for the CPU to interact with these devices:
\begin{enumerate}[noitemsep]
\item \nameref{def:Programmed_IO}
\item \nameref{def:Interrupt_Driven}
\end{enumerate}

\begin{definition}[Programmed I/O]\label{def:Programmed_IO}
  \emph{Programmed I/O} (\emph{PIO}) is when the CPU uses polling to watch the control bit, constantly looping to see whether the device is ready.
\end{definition}

\begin{definition}[Interrupt-Driven]\label{def:Interrupt_Driven}
  An \emph{interrupt-driven} system is one where the CPU does not poll the control bit, but instead receives an \nameref{def:Interrupt} when the device is ready for the next byte.
\end{definition}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../EDAF35-Operating_Systems-Reference_Sheet"
%%% End:
