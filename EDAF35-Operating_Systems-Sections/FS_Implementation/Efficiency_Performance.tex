\subsection{Efficiency and Performance}\label{subsec:Efficiency_Performance}
Disks are the major bottleneck in local system performance, since they are the slowest main computer component.

\subsubsection{Efficiency}\label{subsubsec:Efficiency}
The efficient use of disk space depends on the disk-allocation and directory algorithms.
For example, \textsc{unix} \nameref{par:Inode}s are preallocated on and spread across the volume.
Thus, even an empty disk has a percentage of its space lost to \texttt{inode}s.
However, preallocating the \texttt{inode}s improves the \nameref{def:File_System}'s performance.
This comes from the allocation and free-space algorithms, which try to keep a file’s data blocks near that file’s \texttt{inode} block to reduce seek time.

The \nameref{def:File_Metadata} normally kept in a \nameref{def:File}'s \nameref{def:Directory} (or \nameref{par:Inode}) entry also requires consideration.
Normally, a ``last write date'' is recorded.
Some systems also keep a ``last access date'', so that when the file was last read can be determined.
The result of keeping this information is, whenever the file is read, a field in the directory must be written.
This means the directory block must be read into memory, a changed, and written back out to disk, because operations on disks occur only in block (or \nameref{def:Disk_Cluster}) chunks.

Consider how efficiency is affected by the size of the pointers used to access data.
Most \nameref{def:Operating_System}s use either 32-bit or 64-bit pointers throughout their code.
Using 32-bit pointers for \nameref{def:File}s limits the size of a file to $2^{32}$, or \SI{4}{\gibi{} \byte{}}.
Using 64-bit pointers allows very large file sizes, but require double the space to store.

\subsubsection{Performance}\label{subsubsec:Performance}
Even after the basic file-system algorithms have been selected, we can still improve performance in several ways.
Most disk controllers include an on-board cache large enough to store entire tracks at a time.
When a seek is performed, the track is read into the disk's cache starting at the sector under the disk head (reducing latency time).
The disk controller then transfers any sector requests to the operating system.
Once blocks make it from the disk controller into main memory, the operating system may cache the blocks there.

\paragraph{Unified Virtual Memory}\label{par:Unified_Virtual_Memory}
Some systems cache file data using a \nameref{def:Page_Cache} to create \emph{Unified Virtual Memory}.

\begin{definition}[Page Cache]\label{def:Page_Cache}
  A \emph{page cache} uses virtual memory techniques to cache file data as pages in a \nameref{def:Paging} system.
  They are cached as pages rather than as file-system blocks, meaning they have a \nameref{def:Virtual_Address_Space}.
  Caching file data using virtual addresses is far more efficient than caching through physical disk blocks, as accesses interface with \nameref{def:Virtual_Memory} rather than the \nameref{def:File_System}.
\end{definition}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../EDAF35-Operating_Systems-Reference_Sheet"
%%% End:
