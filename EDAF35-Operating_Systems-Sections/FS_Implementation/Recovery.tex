\subsection{Recovery}\label{subsec:Recovery}
Files and directories are kept both in main memory and on disk, and care must be taken to ensure that a system failure does not result in loss of data or in data inconsistency.
A system crash can cause inconsistencies among on-disk file-system data structures, such as \nameref{def:Directory} structures, free-block pointers, and free \nameref{def:File_Control_Block} pointers.
Many file systems apply changes to these structures in place.
These changes can be interrupted by a crash, and inconsistencies among the structures can result.

A typical operation, such as creating a file, can involve many structural changes within the \nameref{def:File_System} on-disk.
Compounding this is the caching that operating systems do to optimize I/O performance.
Some changes may go directly to disk, while others may be cached.
If the cached changes do not reach disk before a crash occurs, more corruption is possible.

\subsubsection{Consistency Checking}\label{subsubsec:Consistency_Checking}
A file system must first detect the problems and then correct them.
For detection, a scan of all the \nameref{def:File_Metadata} on each file system can confirm or deny the consistency of the system.
This scan can take minutes or hours and should occur \textbf{every time} the system boots.

Alternatively, a \nameref{def:File_System} can record its state within the file-system metadata.
Before any \nameref{def:File_Metadata} change, a status bit is set to indicate that the metadata is in-flux.
If all changes to the metadata are successful, the file system can clear that bit.
However, if the status bit remains set, a consistency checker is run.

The consistency checker (\nameref{def:System_Program}s such as \texttt{fsck} in \textsc{unix}) compare the data in the directory structure with the data blocks on disk and \textbf{tries} to fix any inconsistencies it finds.
The \nameref{subsec:File_Allocation_Methods} and \nameref{subsec:Free_Space_Management} algorithms dictate what types of problems the checker can find and how successful it will be in fixing them.

\subsubsection{Journaling}\label{subsubsec:Journaling}
This is technically called a \emph{Log-Based Transaction-Oriented File System}.
However, most people today call them journaling file systems, so I went with that.

All \nameref{def:File_Metadata} changes are written sequentially to a log which is a circular buffer.
Each set of operations for performing a specific task is a \textbf{transaction}.
Once the changes are written to this log, they are considered a \textbf{committed transaction}, and the \nameref{def:System_Call} will return to the user process, allowing it to continue execution.
Meanwhile, these log entries are replayed, in the background, across the actual \nameref{def:File_System} structures.
As the changes are made, a pointer is updated to indicate which actions have completed and which are still incomplete.
When a committed transaction is completed, it is removed from the log file.

The log may be in a separate section of the file system or a separate disk.
It is more efficient, but more complex, to have it under separate read and write heads, thereby decreasing head contention and seek times.

If the system crashes, the log file will contain zero or more transactions.
Any transactions it contains were not completed to the file system, so they must now be completed.
The transactions can be executed from the pointer until the work is complete.
The only problem occurs when a transaction was stopped before it was committed.

A side benefit of using logging on \nameref{def:File_Metadata} updates is that the updates proceed much faster than usual.
The reason is the performance advantage of sequential I/O over random I/O.
The costly synchronous on-demand random metadata writes are turned into less costly synchronous sequential writes to the journal.
Those changes, in turn, are replayed asynchronously via random writes, in the background, to the appropriate structures.
The overall result is a significant gain in performance of \nameref{def:File_Metadata}-oriented operations, such as file creation and deletion.

\subsubsection{Other Solutions}\label{subsubsec:Other_FS_Recovery_Solutions}
\textbf{Copy-on-Write} for disks is starting to become a big thing now.
This is quite similar to memory's \nameref{def:Memory_Copy_on_Write} functionality, just a different storage medium.
When the updates are made on the disk in a physically separate location, asynchronously.
Then the pointer to the original block is moved to the new one, synchronously.
This way, if the data is committed to the disk correctly, the pointer is moved automatically, nearly without fail.

This allows for snapshots to be made.

\subsubsection{Backup and Restore}\label{subsubsec:Backup_Restore}
Sometimes data from one disk is backed up to another storage device.
This way if there is a catastrophic failure of the original, the secondary can restore what was lost.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../EDAF35-Operating_Systems-Reference_Sheet"
%%% End:
