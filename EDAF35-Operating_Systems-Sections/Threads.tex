\section{Threads}\label{sec:Threads}
\begin{definition}[Thread]\label{def:Thread}
  \emph{Threads of execution}, often shortened to \emph{threads}, are the objects of activity within the process.
  Each thread includes:
  \begin{itemize}[noitemsep]
  \item Thread ID
  \item A unique program counter
  \item Process stack
  \item Set of processor \nameref{def:Register}s
  \end{itemize}

  The \nameref{def:Kernel} schedules the individual threads, not \nameref{def:Process}es.

  In traditional UNIX systems, each \nameref{def:Process} consists of one thread.
  In modern systems, however, multithreaded programs/processes are common.
  In this case, this \nameref{def:Process}'s threads share:
  \begin{itemize}[noitemsep]
  \item The Code Section
  \item The Data Section
  \item Operating System resources, such as files and signals.
  \end{itemize}

  \begin{remark}[Threads in Linux]\label{rmk:Linux_Threads}
    Linux has a unique implementation of threads; it does not differentiate between \nameref{def:Thread}s and \nameref{def:Process}es.
    To Linux, a thread is just a special kind of process.
  \end{remark}
\end{definition}

\nameref{def:Thread}s are very useful in modern programming whenever a \nameref{def:Process} has multiple tasks to perform independently of the others.
The use of \nameref{def:Thread}s is even more aparent when the single process/program must perform many similar tasks.
This is particularly true when one of the threads may block, and it is desired to allow the other threads to proceed without blocking.

The biggest benefits of using multiple \nameref{def:Thread}s are:
\begin{enumerate}[noitemsep]
\item \textbf{Responsiveness}.
  Multithreading an interactive application may allow a program to continue running even if part of it is blocked or is performing a lengthy operation, thereby increasing responsiveness to the user.
  This quality is especially useful in designing user interfaces.
\item \textbf{Resource sharing}.
  \nameref{def:Process}es can only share resources through techniques such as \nameref{par:Message_Passing} and \nameref{par:Message_Passing}.
  Using these techniques requires explicit arrangement by the programmer.
  However, threads share the memory and the resources of the process to which they belong, allowing an application to have several different threads of activity within the same address space.
\item \textbf{Economy}.
  Allocating memory and resources for process creation is costly.
  Because threads share the resources of the process to which they belong, it is more economical to create and context-switch threads.
\item \textbf{Scalability}.
  The benefits of multithreading can be even greater in a multiprocessor architecture, where threads may be running in parallel on different processing cores.
  A single-threaded process can run on only one processor, regardless how many are available.
\end{enumerate}

\begin{definition}[Parallelism]\label{def:Parallelism}
  \emph{Parallelism} is where a system can perform more than one task simultaneously.
\end{definition}

\begin{definition}[Concurrency]\label{def:Concurrency}
  \emph{Concurrency} supports more than one task executing simulataneiously, and allows all the tasks to make progress.
  Thus, it is possible to have concurrency without \nameref{def:Parallelism}.
\end{definition}

To handle the increase in \nameref{def:Process} \nameref{def:Thread} counts, many CPUs support more than one thread per core.
This means multiple threads can be loaded into the CPU for faster switching.
On desktop Intel CPUs, this is called \textbf{hyperthreading}.

The biggest difficulties in using multiple \nameref{def:Thread}s are:
\begin{enumerate}[noitemsep]
\item \textbf{Identifying tasks}.
  Examine applications to find areas that can be divided into independent tasks that can be run concurrently on individual cores.
\item \textbf{Balance}.
  While identifying tasks that can run in parallel, programmers must also ensure that the tasks perform equal work of equal value.
  In some instances, a certain task may not contribute as much value to the overall process as other tasks.
\item \textbf{Data splitting}.
  Just as applications are divided into separate tasks, the data accessed and manipulated by the tasks must be divided to run on separate cores.
\item \textbf{Data dependency}.
  The data accessed by the tasks must be examined for dependencies between two or more tasks.
  When one task depends on data from another, the tasks must be synchronized to accommodate the data dependency.
\item \textbf{Testing and debugging}.
  When a program is running in parallel on multiple cores, many different execution paths are possible, making testing and debugging much harder.
\end{enumerate}

There are 2 distinct types of \nameref{def:Parallelism}, though many applications use both of them.
\begin{enumerate}[noitemsep]
\item \nameref{def:Data_Parallelism}
\item \nameref{def:Task_Parallelism}
\end{enumerate}

\begin{definition}[Data Parallelism]\label{def:Data_Parallelism}
  \emph{Data parallelism} focuses on distributing subsets of the same data across multiple computing cores and performing the same operation on each core.
  For example, summing the contents of an array of size $N$.
  On a single-core system, one thread would simply sum the elements $[0] \ldots [N − 1]$.
  On a dual-core system, however, thread A, running on core 0, could sum the elements $[0] \ldots [\frac{N}{2} − 1]$ while thread B, running on core 1, could sum the rest of the elements $[\frac{N}{2}] \ldots [N − 1]$.
\end{definition}

\begin{definition}[Task Parallelism]\label{def:Task_Parallelism}
  \emph{Task parallelism} involves distributing tasks/\nameref{def:Thread}s across multiple computing cores.
  Each thread is performing a unique operation.
  Different threads may be operating on the same data, or they may be operating on different data.
\end{definition}

\input{./EDAF35-Operating_Systems-Sections/Threads/User_Kernel_Threads}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../EDAF35-Operating_Systems-Reference_Sheet"
%%% End:
