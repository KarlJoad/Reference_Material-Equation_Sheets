\subsection{Algorithm Evaluation}\label{subsec:Algorithm_Evaluation}
Now that we have selected a \nameref{def:Scheduling_Algorithm} to use, how do we know that it was the right choice?
First, we need to know what our criteria were.
Some systems might have multiple criteria at a time, such as:
\begin{itemize}[noitemsep]
\item Maximum CPU response time is 1 second.
\item Turnaround time is (on average) linearly proportional to total execution time.
\end{itemize}

To do this, there are 4 main ways to do this:
\begin{enumerate}[noitemsep]
\item \nameref{subsubsec:Algorithm_Deterministic_Modeling}
\item \nameref{subsubsec:Algorithm_Queuing_Models}
\item \nameref{subsubsec:Algorithm_Simulations}
\item \nameref{subsubsec:Algorithm_Implementation}
\end{enumerate}

\subsubsection{Deterministic Modeling}\label{subsubsec:Algorithm_Deterministic_Modeling}
Deterministic modeling is simple and fast.
It gives us exact numbers, allowing us to compare the algorithms.
However, it requires \textbf{exact numbers for input}, and its answers apply \emph{only} to those cases.

This method takes a particular predetermined workload and defines the performance of each algorithm for that workload.

The main uses of deterministic modeling are in describing \nameref{def:Scheduling_Algorithm}s and providing examples.
In cases where we are running the same program repeatedly, we can measure the programâ€™s processing requirements exactly, allowing us to select a \nameref{def:Scheduling_Algorithm}.
Furthermore, over a set of examples, deterministic modeling may indicate trends that can then be analyzed and proved separately.

\subsubsection{Queuing Models}\label{subsubsec:Algorithm_Queuing_Models}
On many systems, the processes that are run vary from day to day, so deterministic modeling is impossible.
Instead, we can find the the distribution of \nameref{def:CPU_Burst}s and \nameref{def:I/O_Burst}s.

Commonly, this distribution is exponential and is described by its mean.
Similarly, we can describe the distribution of times when processes arrive in
the system (the arrival-time distribution). From these two distributions, it is
possible to compute the average throughput, utilization, waiting time, and so
on for most algorithms.

The CPU is described as a server with a queue of \texttt{READY} processes.
The I/O system with its device queues is another instance of these servers.
Knowing arrival rates and service rates, we can compute utilization, average queue length, average wait time, among other parameters.
For a more detailed discussion of these topics, refer to \href{file:./ETSN10-Network_Architecture_Performance-Reference_Material.pdf}{ETSN10: Network Architecture and Performance}.

\emph{Little's Formula}, \Cref{eq:Littles_Law}, shown below, is useful because we can calculate a large variety of information from just a few parameters.
\begin{equation}\label{eq:Littles_Law}
  n = \lambda \times W
\end{equation}
\begin{description}[noitemsep]
\item $n$: The average queue length, excluding the process currently executing on the CPU.\@
\item $\lambda$: The average arrival rate of new processes.
\item $W$: The average amount of time a process waits in the queue.
\end{description}

Queueing analysis can be useful in comparing scheduling algorithms, but the classes of algorithms and distributions that can be handled is limited.
The mathematics of complicated algorithms and distributions are difficult to work with, and arrival and service distributions are often defined in mathematically tractable (but unrealistic) ways.
Generally, it is necessary to make a number of independent assumptions, which may not be accurate.
This means queuing models are only approximations of real systems, and the accuracy of the computed results are questionable.

\subsubsection{Simulations}\label{subsubsec:Algorithm_Simulations}
To get a more accurate evaluation of scheduling algorithms, simulations can be used.
Running simulations involves programming a model of the computer system.
Software is used to represent major components of the system.
As ``time'' progresses, the simulator modifies the system state to reflect the activities of the devices, the processes, and the scheduler.
As the simulation executes, statistics that indicate algorithm performance are gathered.
Typically, input is generated from a random-number generated that is programmed according to probability distributions.

However, simulations can be expensive, often requiring hours of processor time.
A more detailed simulation provides more accurate results, but takes more computer time.

\subsubsection{Implementation}\label{subsubsec:Algorithm_Implementation}
Even a simulation is of limited accuracy.
The only completely accurate way to evaluate a \nameref{def:Scheduling_Algorithm} is to code it, put it in the \nameref{def:Operating_System}, and see how it works.
This approach puts the actual algorithm in the real system for evaluation under real operating conditions.
The major difficulty with this approach is the high cost.

One of the biggest difficulties is the expense incurred in coding the algorithm and modifying the operating system to support it (along with its required data structures).
The environment around the algorithm used will change not only in the usual way (New programs written and the types of problems change) but also as a result of the performance of the scheduler.
If short processes are given priority, then users may break larger processes into sets of smaller processes.
If interactive processes are given priority over noninteractive processes, then users may switch to interactive use.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../EDAF35-Operating_Systems-Reference_Sheet"
%%% End:
