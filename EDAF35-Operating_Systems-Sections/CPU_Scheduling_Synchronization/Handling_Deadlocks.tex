\subsection{Handling Deadlocks}\label{subsec:Handling_Deadlocks}
There are 3 main ways to handle a deadlock:
\begin{enumerate}[noitemsep]
\item We can use a protocol to prevent (\Cref{subsubsec:Deadlock_Prevention}) or avoid (\Cref{subsubsec:Deadlock_Avoidance}) deadlocks, ensuring that the system will never enter a deadlocked state.
\item We can allow the system to enter a deadlocked state, detect it, and recover (\Cref{subsubsec:Deadlock_Detection}).
\item We can ignore the problem altogether and pretend that deadlocks never occur in the system.
\end{enumerate}

The third method of handling a \nameref{def:Deadlock} may not make sense, but from a cost perspective, it does.
Ignoring the possibility of deadlocks is cheaper.
In many systems, deadlocks occur infrequently (once per year), the extra expense of the methods may not seem worthwhile.
In addition, methods used to recover from other conditions may be put to use to recover from deadlock.
In some circumstances, a system is in a frozen state but not in a deadlocked state.

\subsubsection{Deadlock Prevention}\label{subsubsec:Deadlock_Prevention}
\begin{definition}[Deadlock Prevention]\label{def:Deadlock_Prevention}
  \emph{Deadlock prevention} is done by providing a set of methods that ensure any one of the \nameref{subsubsec:Deadlock_Conditions} cannot occur.
\end{definition}

\paragraph{Mutual Exclusion}\label{par:Deadlock_Prevention-Mutual_Exclusion}
That is, at least one resource must be nonsharable.
Sharable resources, in contrast, do not require mutually exclusive access and thus cannot be involved in a deadlock.
A process never needs to wait for a sharable resource.

Read-only files are a good example of a sharable resource.
If several processes attempt to open a read-only file at the same time, they can be granted simultaneous access to the file.

\paragraph{Hold and Wait}\label{par:Deadlock_Prevention-Hold_Wait}
To ensure that the hold-and-wait condition never occurs in the system, we must guarantee that, whenever a process requests a resource, it does not hold any other resources.

We can implement this provision by requiring that system calls requesting resources for a process precede all other system calls.
An alternative protocol allows a process to request resources only when it has none.

Both these protocols have two main disadvantages.
First, resource utilization may be low, since resources may be allocated but unused for a long period.
Second, \nameref{def:Starvation} is possible.
A process that needs several popular resources may have to wait indefinitely, because at least one of the resources that it needs is always allocated to some other process.

\paragraph{No Preemption}\label{par:Deadlock_Prevention-No_Preemption}
To ensure that no \nameref{def:Preemption} of resources that have already been allocated occurs, we can use the following protocol.
If a process is holding some resources and requests another resource that cannot be immediately allocated to it (that is, the process must wait), then all resources the process is currently holding are preempted, implicitly releasing them.
The preempted resources are added to the list of resources for which the process is waiting.
The process will be restarted only when it can regain its old resources, as well as the new ones that it is requesting.

This protocol is often applied to resources whose state can be easily saved and restored later, such as CPU registers and memory space.
It cannot generally be applied to such resources as mutex locks and semaphores.

\paragraph{Circular Wait}\label{par:Deadlock_Prevention-Circular_Wait}
One way to ensure that this condition never holds is to impose a total ordering of all resource types and to require that each process requests resources in an increasing order of enumeration.
Possible side effects of preventing deadlocks are low device utilization and reduced system throughput.

Formally, we define a one-to-one function
\begin{equation*}
F: R \rightarrow \NaturalNumbers
\end{equation*}
where $R$ is the set of resources and  $\NaturalNumbers$ is the set of natural numbers.

Each process can request resources only in an increasing order of enumeration.
Meaning, a process can initially request any number of instances of a resource type, $R_{i}$.
After that, the process can request instances of resource type $R_{j}$ if and only if $F(R_{j}) > F(R_{i})$.
This could be similarly defined using a more generous comparison; a process can request instances of resource type $R_{j}$ if and only if $F(R_{j}) \geq F(R_{i})$.

This property can be proven, \Cref{proof:Circular_Wait}.

\begin{proof}[Proof by Contradiction of Circular Waiting]\label{proof:Circular_Wait}
  Let the set of processes involved in the circular wait be $\lbrace P_{0}, P_{1}, \ldots, P_{n} \rbrace$, where $P_{i}$ is waiting for a resource $R_{i}$, which is held by process\footnote{Modulo arithmetic is used on the indexes.} $P_{i+1}$.

  Then, since process $P_{i+1}$ is holding resource $R_{i}$ while requesting resource $R_{i+1}$, we must have
  \begin{equation*}
    \forall i. F(R_{i}) < F(R_{i+1})
  \end{equation*}

  But this condition means
  \begin{equation*}
    F(R_{0}) < F(R_{1}) < \cdots < F(R_{n}) < F (R_{0})
  \end{equation*}

  By transitivity, $F(R_{0}) < F(R_{0})$, which is impossible. \\
  $\therefore$ there can be no circular wait.
\end{proof}

\begin{blackbox}
  Keep in mind that developing an ordering, or hierarchy, does not in itself prevent deadlock.
  It is up to application developers to write programs that follow the ordering.
\end{blackbox}

\subsubsection{Deadlock Avoidance}\label{subsubsec:Deadlock_Avoidance}
\begin{definition}[Deadlock Avoidance]\label{def:Deadlock_Avoidance}
  \emph{Deadlock avoidance} requires the \nameref{def:Operating_System} be gined additional information in advnace about what resources a process will request and possible use within its lifetime.
\end{definition}

To avoid \nameref{def:Deadlock}s, the \nameref{def:Operating_System} can require additional information about how resources are to be requested.
With knowledge of the complete sequence of requests and releases for each process, the system can decide for each request whether or not the process should wait in order to avoid a possible future deadlock.
Each request requires that in making this decision the system consider the resources currently available, the resources currently allocated to each process, and the future requests and releases of each process.

There are 2 major ways to achieve this:
\begin{enumerate}[noitemsep]
\item \nameref{par:Deadlock_Avoidance-Safe_State}
\item \nameref{par:Deadlock_Avoidance-Resource_Allocation_Graph}
\end{enumerate}

\paragraph{Safe State}\label{par:Deadlock_Avoidance-Safe_State}
A system is in a safe state only if there exists a safe sequence.
A sequence of processes $\langle P 1, P 2 , \ldots, P n \rangle$ is a safe sequence for the current allocation state if, for all resource requests that $P_{i}$ makes, they can be satisfied by the currently available resources plus the resources held by all $P_{j}$, where $j < i$.
If the resources that $P_{i}$ needs are not immediately available, then $P_{i}$ can wait until all $P_{j}$ have finished.
When $P_{j}$ has finished, $P_{i}$ can obtain all of its needed resources, complete its designated task, return its allocated resources, and terminate.
When $P_{i}$ terminates, $P_{i+1}$ can obtain its needed resources, and so on.
If no such sequence exists, then the system state is said to be \emph{unsafe}.

\begin{blackbox}
  A safe state is not a deadlocked state.
  Conversely, a deadlocked state is an unsafe state.
  Not all unsafe states are deadlocks, however.
\end{blackbox}

\subsubsection{Deadlock Detection}\label{subsubsec:Deadlock_Detection}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../EDAF35-Operating_Systems-Reference_Sheet"
%%% End:
