\section{Discrete-Time Systems}\label{sec:Discrete-Time Systems}
As discussed in \Cref{subsec:Discrete-Time Signals}, $x(n)$ is a function of an independent variable that is an integer.
It is important to note that a discrete-time signal is \emph{not defined} at instants between the samples.
Also, if $n$ is not an integer, $x(n)$ is not defined.

Besides graphical representation of a discrete-time system, there are 3 ways to represent a discrete-time signal.
\begin{enumerate}[noitemsep]
\item \nameref{subsubsec:Functional Representation}
\item \nameref{subsubsec:Tabular Representation}
\item \nameref{subsubsec:Sequence Representation}
\end{enumerate}

\subsection{Representing Discrete-Time Systems}\label{subsec:Representing Discrete-Time Systems}
\subsubsection{Functional Representation}\label{subsubsec:Functional Representation}
This representation of a discrete-time system is done as a mathematical function.
\begin{equation}\label{eq:Functional Representation}
  x(n) = \begin{cases}
    1 ,& \text{for } n = 1,3 \\
    4 ,& \text{for } n = 2 \\
    0 ,& \text{elsewhere}
  \end{cases}
\end{equation}

\subsubsection{Tabular Representation}\label{subsubsec:Tabular Representation}
This representation of a discrete-time sysem is done as a table of corresponding values.
\begin{table}[h!]
  \centering
  \begin{tabular}{c|cccccccccc}
    $n$ & $\ldots$ & -2 & -1 & 0 & 1 & 2 & 3 & 4 & 5 & $\ldots$ \\ \midrule
    $x(n)$ & $\ldots$ & 0 & 0 & 0 & 1 & 4 & 1 & 0 & 0 & $\ldots$
  \end{tabular}
\end{table}

\subsubsection{Sequence Representation}\label{subsubsec:Sequence Representation}
There are 2 methods of representation for this.
The first includes all values for $-\infty < n < \infty$.
In all cases, $n=0$ is marked in the sequence, somehow.
I will do this with an underline.
\begin{equation}\label{eq:Infinite Sequence Representation}
  x(n) = \lbrace \ldots, 0, \underline{0}, 1, 4, 1, 0, 0, \ldots \rbrace
\end{equation}

The second only works if all $x(n)$ values for $n < 0$ are 0.
\begin{equation}\label{eq:Zero Sequence Representation}
  x(n) = \lbrace \underline{0}, 1, 4, 1, 0, 0, \ldots \rbrace
\end{equation}

A finite-duration sequence can be represented as
\begin{equation}\label{eq:Finite Sequence Representation}
  x(n) = \lbrace 3, -1, \underline{-2}, 5, 0, 4, -1 \rbrace
\end{equation}
This is identified as a seven-point sequence.

A finite-duration sequence where $x(n)=0$ for all $n<0$ is represented as
\begin{equation}\label{eq:Zero Finite Sequence Representation}
  x(n) = \lbrace \underline{0}, 1, 4, 1 \rbrace
\end{equation}
This is identified as a four-point sequence.

\subsection{Elementary Discrete-Time Signals}\label{subsec:Elementary Discrete-Time Signals}
The following signals are basic signals that appear often and play an important role in signal processing.

\subsubsection{Unit Impulse Signal}\label{subsubsec:Unit Impulse Signal}
\begin{definition}[Unit Impulse Signal]\label{def:Unit Impulse Signal}
  The \emph{unit impulse signal} or \emph{unit sample sequence} is denoted as $\delta(n)$ and is defined as
  \begin{equation}\label{eq:Unit Impulse Signal}
    \delta(n) \equiv = \begin{cases}
      1, & \text{for } n = 0 \\
      0, & \text{for } n \neq 0
    \end{cases}
  \end{equation}

  This function is a signal that is zero everywhere, except at $n=0$, where its value is $1$.

  \begin{remark}
    This signal is different that the analog signal $\delta (t)$, which is also called a unit impulse, and is defined to be 0 everywhere except $t=0$.
    The discrete unit impulse sequence is much less mathematically complicated.
  \end{remark}
\end{definition}

\subsubsection{Unit Step Signal}\label{subsubsec:Unit Step Signal}
\begin{definition}[Unit Step Signal]\label{def:Unit Step Signal}
  The \emph{unit step signal} is denoted as $u(n)$ or as $\UnitStep(n)$ and is defined as
  \begin{equation}\label{eq:Unit Step Signal}
    \UnitStep(n) \equiv \begin{cases}
      1, & \text{for } n \geq 0 \\
      0, & \text{for } n < 0
    \end{cases}
  \end{equation}
\end{definition}

\subsubsection{Unit Ramp Signal}\label{subsubsec:Unit Ramp Signal}
\begin{definition}[Unit Ramp Signal]\label{def:Unit Ramp Signal}
  The \emph{unit ramp signal} is denoted as $u_{r}(n)$ and is defined as
  \begin{equation}\label{eq:Unit Ramp Signal}
    u_{r}(n) \equiv \begin{cases}
      n, & \text{for } n \geq 0 \\
      0, & \text{for } n < 0
    \end{cases}
  \end{equation}
\end{definition}

\subsubsection{Exponential Signal}\label{subsubsec:Exponential Signal}
\begin{definition}[Exponential Signal]\label{def:Exponential Signal}
  The \emph{exponential signal} is a sequence of the form
  \begin{equation}\label{eq:Exponential Signal}
    x(n) = a^{n} \>\> \text{for all } n
  \end{equation}

  If $a$ is real, then $x(n)$ is a real signal.
  When $a$ is complex valued ($a \equiv b \pm c j$), it can be expressed as
   \begin{equation}\label{eq:Complex Exponential Signal}
     \begin{aligned}
       x(n) &= r^{n} e^{j \theta n} \\
       &= r^{n} \left( \cos \theta n + j \sin \theta n \right)
     \end{aligned}
   \end{equation}
  This can be expressed by graphing the real and imaginary parts
  \begin{equation}\label{eq:Real Imaginary Complex Exponential Signal}
    \begin{aligned}
      x_{R}(n) &\equiv r^{n} \cos \theta n \\
      x_{I}(n) &\equiv r^{n} j \sin \theta n
    \end{aligned}
  \end{equation}
  or by graphing the amplitude function and phase function.
  \begin{equation}\label{eq:Amplitude Phase Complex Exponential Signal}
    \begin{aligned}
      \lvert x(n) \rvert &= A(n) \equiv r^{n} \\
      \angle x(n) &= \phi(n) \equiv \theta n
    \end{aligned}
  \end{equation}
\end{definition}

\subsection{Classification of Discrete-Time Signals}\label{subsec:Classification Discrete-Time Signals}
In order to apply some mathematical methods to discrete-time signals, we must characterize these signals.

\subsubsection{Energy Signal}\label{subsubsec:Energy Signal}
\begin{definition}[Energy Signal]\label{def:Energy Signal}
  The energy $E$ of a signal $x(n)$ is defined as
  \begin{equation}\label{eq:Energy Signal}
    \begin{aligned}
      E &\equiv \sum_{n=-\infty}^{\infty} \lvert x(n) \rvert^{2} \\
      &\equiv \sum_{n=-\infty}^{\infty} x(n) x^{*}(n) \\
    \end{aligned}
  \end{equation}
  The energy of a signal can be finite or infinite. If $E$ is finite ($0 < E < \infty$), then $x(n)$ is called an \emph{energy signal}.
\end{definition}

\subsubsection{Power Signal}\label{subsubsec:Power Signal}
\begin{definition}[Power Signal]\label{def:Power Signal}
  The average power of a discrete time signal $x(n)$ is defined as
  \begin{equation}\label{eq:Power Signal}
    P = \lim_{N \to \infty} \frac{1}{2N+1} \sum_{n=-N}^{N} \lvert x(n) \rvert ^{2}
  \end{equation}

  This means that there are 2 potential outcomes:
  \begin{enumerate}[noitemsep]
  \item If $E$ is finite, $P=0$
  \item If $E$ is infinite, $P$ may be either finite or infinite
  \end{enumerate}

  If $P$ is finite and nonzero, the signal is called a \emph{power signal}.
\end{definition}

\subsubsection{Periodic and Aperiodic Signals}\label{subsubsec:Periodic Aperiodic Signals}
A signal $x(n)$ is periodic with period $N$ ($N>0$) if and only if
\begin{equation}\label{eq:Periodic Signal}
  x(n+N) = x(n) \text{for all } n
\end{equation}

The smallest value of $N$ for which~\eqref{eq:Periodic Signal} holds is called the fundamental period.
If there is no value of $N$ that satisfies~\eqref{eq:Periodic Signal}, the signal is called \emph{nonperiodic} or \emph{aperiodic}.

\subsubsection{Symmetric and Antisymmetric Signals}\label{subsubsec:Symmetric and Antisymmetric Signals}
A real-valued signal $x(n)$ is called \emph{symmetric} or \emph{even} if
\begin{equation}\label{eq:Symmetric Signal}
  x(n) = x(-n)
\end{equation}

On the other hand, a signal $x(n)$ is called \emph{antisymmetric} or \emph{odd} if
\begin{equation}\label{eq:Asymmetric Signal}
  x(n) = -x(-n)
\end{equation}


\subsection{Classification of Discrete-Time Systems}\label{subsec:Classification_Discrete-Time_Systems}
\subsubsection{Static versus Dynamic Systems}\label{subsubsec:Static_vs_Dynamic_Systems}
\begin{definition}[Static]\label{def:Static}
  A discrete-time system is called \emph{static} or \emph{memoryless} if its output at any instant $n$ depends only on the input sample at the same time, but not on past or future samples of the input.
\end{definition}

\begin{definition}[Dynamic]\label{def:Dynamic}
  A discrete-time system is called \emph{dynamic} if its output at any instant $n$ depends not only on the input sample at the same time, but \textbf{also} on past and/or future samples of the input.

  If the output of s system at tine $n$ is completely determined by the input samples in the interval from $n-N$ to $n(N\geq 0)$, the system is said to have a \emph{memory} of duration $N$.
  If $N=0$, then the system is \nameref{def:Static}, whereas if $N=\infty$, the system is said to have \emph{infinite memory}.
\end{definition}

\subsubsection{Time-Invariant versus Time-Variant Systems}\label{subsubsec:Time-Invariant_vs_Time-Variant_Systems}
\begin{definition}[Time-Invariant]\label{def:Time_Invariant}
  A \emph{time-invariant} system in one whose output is affected only in time, if the input's time is changed.
  A relaxed system $\SignalOperator$ is \emph{time-invariant} or \emph{shift invariant} is and only if
  \begin{equation*}
    x(n) \overset{\mathcal{T}}{\longrightarrow} y(n)
  \end{equation*}
  implies that
  \begin{equation*}
    x(n-k) \overset{\mathcal{T}}{\longrightarrow} y(n-k)
  \end{equation*}
  for every input signal $x(n)$ and every time shift $k$.
\end{definition}

To determine if any given system is \nameref{def:Time_Invariant}, we need to perform a test drawn from \Cref{def:Time_Invariant}.
\begin{enumerate}[noitemsep]
\item Excite the system with an arbitrary input sequence $x(n)$, which produces an output $y(n)$.
\item Delay the input sequence by some amount $k$ and recompute the output.
\item If $y(n,k) = y(n-k)$ for all possible values of $k$, the system is \nameref{def:Time_Invariant}.
\end{enumerate}

\subsubsection{Linear versus Non-Linear Systems}\label{subsubsec:Linear_vs_Non-Linear_Systems}
A linear system is one that satisfies the \textit{superposition principle}.
\begin{definition}[Linear]\label{def:Linear}
  A system is \emph{linear} if and only if
  \begin{equation}\label{eq:Linear}
    \SignalOperator \left[ a_{1}x_{1}(n) + a_{2}x_{2}(n) \right] = a_{1}\SignalOperator \left[ x_{1}(n) \right] + a_{2} \SignalOperator \left[ x_{2}(n) \right]
  \end{equation}
  for any arbitrary input sequences $x_{1}(n)$ and $x_{2}(n)$, and any arbitrary constants $a_{1}$ and $a_{2}$.

  The \nameref{def:Linear}ity property can be broken down into 2 parts:
  \begin{enumerate}[noitemsep]
  \item \nameref{par:Linear-Multiplicative_Property}
  \item \nameref{par:Linear-Additive_Property}
  \end{enumerate}

  \begin{remark}
    The \nameref{def:Linear}ity property can be extended to any number of terms.
  \end{remark}
\end{definition}

\paragraph{Multiplicative Property}\label{par:Linear-Multiplicative_Property}
\begin{definition}[Multiplicative Property]\label{def:Linear-Multiplicative_Property}
  The \emph{multiplicative} or \emph{scaling property} is one requirement of a \nameref{def:Linear} system and is part of the definition of the superposition principle.
  If the input is scaled, the output is scaled by a proportional amount.

  \begin{equation}\label{eq:Linear-Multiplicative_Property}
    \begin{aligned}
      \SignalOperator \left[ a_{1}x_{1}(n) \right] &= a_{1} \SignalOperator \left[ x_{1}(n) \right] \\
      &= a_{1}y_{1}(n) \\
    \end{aligned}
  \end{equation}
\end{definition}

\paragraph{Additive Property}\label{par:Linear-Additive_Property}
\begin{definition}[Additive Property]\label{def:Linear-Additive_Property}
  The \emph{additive property} is one requirement of a \nameref{def:Linear} system and is part of the definition of the superposition principle.

  \begin{equation}\label{eq:Linear-Additive_Property}
    \begin{aligned}
      \SignalOperator \left[ x_{1}(n) + x_{2}(n) \right] &= \SignalOperator \left[ x_{1}(n) \right] + \SignalOperator \left[ x_{2}(n) \right] \\
      &= y_{1}(n) + y_{2}(n)
    \end{aligned}
  \end{equation}
\end{definition}

\begin{definition}[Nonlinear]\label{def:Nonlinear}
  If a relaxed system does no satisfy the superposition principle, or the definition of a \nameref{def:Linear} system, it is \emph{nonlinear}.
\end{definition}

\subsubsection{Causal versus Noncausal Systems}\label{subsubsec:Causal_vs_Noncausal_Systems}
\begin{definition}[Causal]\label{def:Causal}
  A system is said to \emph{causal} if the output of the system, $y(n)$, at any time $n$ depends only on present and past inputs [i.e., $x(n), x(n-1), x(n-2), \ldots$], but does not depends on future inputs [i.e., $x(n+1), x(n+2), \ldots$].

  Mathematically, the output of a causal system satisfies an equation of the form
  \begin{equation}\label{eq:Causal}
    y(n) = F \left[ x(n), x(n-1), x(n-2), \ldots \right]
  \end{equation}
  where $F\left[ \cdot \right]$ is some arbitrary function.
\end{definition}

\begin{definition}[Noncausal]\label{def:Noncausal}
  If a system does not satisfy the definition of a \nameref{def:Causal} system, then it is \emph{noncausal}.
  A noncausal system depends not just on present and past inputs, but also on future inputs.

  \begin{remark}
    You can never have a noncausal system in real-time signal processing applications.
    However, if the signal has been recorded and will be processed offline, then a noncausal system can be constructed.
  \end{remark}
\end{definition}

\subsubsection{Stable versus Unstable Systems}\label{subsubsec:Stable_vs_Unstable_Systems}
Stability is incredibly important.
Unstable stystems usually have erratic and extreme behavior.

\begin{definition}[Stable]\label{def:Stable}
  An arbitrary relaxed system is said to be \emph{Bounded Input-Bounded Output Stable (BIBO)} if and only if every bounded input produces a bounded output.

  Mathematically, this means the input sequence $x(n)$ and the output sequence $y(n)$ are bounded, where there are some finite numbers $M_{x}$ and $M_{y}$ such that
  \begin{equation}\label{eq:Stable}
    \lvert x(n) \rvert \leq M_{x} < \infty \:\: \lvert y(n) \rvert \leq M_{y} < \infty \: \forall n
  \end{equation}
\end{definition}

\begin{definition}[Unstable]
  If the some bounded input $x(n)$, the output is unbounded (infinite), the system is \emph{unstable}.
\end{definition}

\subsubsection{Linear Time-Invariant Systems}\label{subsubsec:Linear_Time-Invariant}
\begin{definition}[Linear Time-Invariant]\label{def:Linear_Time-Invariant}
  A \emph{Linear Time-Invariant (LTI)} signal or system is one that is:
  \begin{propertylist}
  \item \nameref{def:Linear}
  \item \nameref{def:Time_Invariant}
  \end{propertylist}
\end{definition}

\subsection{Discrete-Time Signal Manipulations}\label{subsec:Discrete-Time Signal Manipulations}
\subsubsection{Transformation of the Independent Variable (Time)}\label{subsubsec:Transform Independent Variable}
It is important to note that \nameref{par:Shifting in Time} and \nameref{par:Folding} are not commutative.
For example,
\begin{equation}\label{eq:Delay then Fold}
  \TimeDelay \lbrace \FoldTime \left[ x(n) \right] \rbrace = \TimeDelay \left[ x(-n) \right] = x(-n + k)
\end{equation}
whereas
\begin{equation}\label{eq:Fold then Delay}
  \FoldTime \lbrace \TimeDelay \left[ x(n) \right] \rbrace = \FoldTime \left[ x(n-k) \right] = x(-n-k)
\end{equation}

\paragraph{Shifting in Time}\label{par:Shifting in Time}
A signal $x(n)$ may be shifted in time by replacing the independent variable $n$ by $n-k$, where $k$ is an integer.
If $k$ is a positive integer, the time shift results in a delay of the signal by $k$ units of time (moves left).
If $k$ is a negative integer, the time shift results in an advance of the signal by $\lvert k \rvert$ units of time (moves right).

This could be denoted by
\begin{equation}\label{eq:Shifting in Time}
  \TimeDelay \left[ x(n) \right] = x(n-k)
\end{equation}

You cannot advance a signal that is being generated in real-time.
Because that would involve signal samples that haven't been generated yet.
So, you can only advance a signal that is stored on something.
However, you can always introduce a delay to a signal.

\paragraph{Folding}\label{par:Folding}
Another useful modification of the time base is to replace $n$ with $-n$.
The result is a \emph{folding} or \emph{reflection} of the original signal around $n=0$.

This could be denoted by
\begin{equation}\label{eq:Folding}
  \FoldTime \left[ x(n) \right] = x(-n)
\end{equation}

\subsubsection{Addition, Multiplication, and Scaling}\label{subsubsec:Addition Multiplication and Scaling}
Amplitude modifications include \nameref{par:Amplitude Addition}, \nameref{par:Amplitude Multiplication}, and \nameref{par:Amplitude Scaling}.

\paragraph{Addition}\label{par:Amplitude Addition}
The \emph{sum} of 2 signals $x_{1}(n)$ and $x_{2}(n)$ is a signal $y(n)$ whose value at any instant is equal to the sum of the values of these two signals at that instant.
\begin{equation}\label{eq:Amplitude Addition}
  y(n) = x_{1}(n) + x_{2}(n), \> -\infty < n < \infty
\end{equation}

\paragraph{Multiplication}\label{par:Amplitude Multiplication}
The \emph{product} of two signals $x_{1}(n)$ and $x_{2}(n)$ is a signal $y(n)$ whose value at any instant is equal to the product of the values of these two signals at that instant.
\begin{equation}\label{eq:Amplitude Multiplication}
  y(n) = x_{1}(n) x_{2}(n), \> -\infty < n < \infty
\end{equation}

\paragraph{Amplitude Scaling}\label{par:Amplitude Scaling}
\emph{Amplitude scaling} of a signal by a constant $A$ is accomplished by multiplying every signal sample by $A$.
Consequently, we obtain
\begin{equation}\label{eq:Amplitude Scaling}
  y(n) = A x(n), \> -\infty < n < \infty
\end{equation}

\subsection{Discrete-Time System Difference Equation}\label{subsec:Discrete-Time_System_Difference_Equation}
There exists an equation that describes any \nameref{def:Linear_Time-Invariant} discrete-time system.
This equation works for both \nameref{def:IIR} and \nameref{def:FIR} filters.

\begin{equation}\label{eq:General_Difference_Equation}
  y(n) + \sum\limits_{k=1}^{N}a_{k}y(n-k) = \sum\limits_{l=0}^{L}b_{l}x(n-l)
\end{equation}
Occasionally, \Cref{eq:General_Difference_Equation} will be written like below.
\begin{equation*}
  y(n) = \sum\limits_{l=0}^{L}b_{l}x(n-l) - \sum\limits_{k=1}^{N}a_{k}y(n-k)
\end{equation*}

\begin{definition}[Infinite Impulse Response]\label{def:IIR}
  An \emph{Infinite Impulse Response (IIR)} filter is one that has an impulse response which does not become exactly zero past a certain point, but continues indefinitely.
  This is opposite to a \nameref{def:FIR} Filter.
\end{definition}

\begin{definition}[Finite Impulse Response]\label{def:FIR}
  A \emph{Finite Impulse Response (FIR)} filter is a filter whose impulse response (or response to any finite length input) is of finite duration, because it settles to zero in finite time.
  This is opposite to a \nameref{def:IIR} Filter.
\end{definition}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../EITF75-Systems_and_Signals-Reference_Sheet"
%%% End:
