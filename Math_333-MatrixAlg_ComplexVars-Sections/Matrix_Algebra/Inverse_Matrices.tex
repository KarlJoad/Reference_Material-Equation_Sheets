\subsection{Inverse Matrices}\label{subsec:Inverse_Matrices}
\begin{definition}[Inverse Matrix]\label{def:Inverse_Matrix}
  Let $A_{n \by n}$ be an $n \by n$ \nameref{def:Matrix}.
  A matrix $B$ is called an inverse of $A$ if and only if
  \begin{equation}\label{eq:Inverse_Matrix}
    AB = I
  \end{equation}
\end{definition}

\begin{theorem}[Inverse Matrix Commutativity]\label{thm:Inverse_Matrix_Commutativity}
  If $B$ is an inverse of $A$, then $AB = BA = I$.
\end{theorem}

\begin{theorem}[Uniqueness of Inverse Matrix]\label{thm:Inverse_Matrix_Uniqueness}
  Let $A_{n \by n}$ be an $n \by n$ \nameref{def:Matrix}.

  Then, $A$ has \textbf{at most} one inverse, denoted $A^{-1}$.
\end{theorem}

\begin{example}[Lecture 13, Example 3]{Matrix with No Inverse}
  Let $A$ be the \nameref{def:Matrix} defined below.
  \begin{equation*}
    A =
    \begin{bmatrix}
      1 & 1 \\
      2 & 2
    \end{bmatrix}
  \end{equation*}
  Find a matrix $B$ such that $B = A^{-1}$?
  \tcblower{}
  Using the definition of an \nameref{def:Inverse_Matrix}, we can prove this with an example.
  \begin{align*}
    \begin{bmatrix}
      1 & 1 \\
      2 & 2
    \end{bmatrix}
          \begin{bmatrix}
            b_{11} & b_{12} \\
            b_{21} & b_{22}
          \end{bmatrix}
        &=
          \begin{bmatrix}
            1 & 0 \\
            0 & 1
          \end{bmatrix} \\
    &=
      \begin{bmatrix}
        b_{11} + b_{21} & b_{12} + b_{22} \\
        2b_{11} + 2b_{22} & 2b_{12} + 2b_{22}
      \end{bmatrix}
  \end{align*}

  We have a system of equations we can show that there is no \nameref{def:Inverse_Matrix}.

  \begin{align*}
    b_{11} + b_{21} &= 1 \\
    2b_{11} + 2b_{21} &= 0
  \end{align*}

  However, this system is in\nameref{def:Consistent}, meaning there is no solution for $b_{11}$ and $b_{21}$.

  Therefore, there does not exist an $A^{-1} = B$ such that $AB = I$.
\end{example}

\subsubsection{Inverse Matrices using Elementary Matrices}\label{subsubsec:Inverse_Matrices_using_Elementary_Matrices}
The \nameref{def:Inverse_Matrix} of any \nameref{def:Matrix} can be found by using \nameref{def:Elementary_Row_Op}s and the actual inverse can be found by using an \nameref{def:Elementary_Matrix}.

\begin{theorem}
  Let $A$ be a matrix with dimensions $n \by n$ ($A_{n \by n}$).

  Then, reducing $A$ to \nameref{thm:Echelon_Form} can be encoded with a series of elementary matrices.
  Mathematically, this implies
  \begin{equation*}
    E_{t} E_{t-1} \cdots E_{2} E_{1} A = I
  \end{equation*}

  This yields 2 cases:
  \begin{equation*}
    \begin{cases}
      \begin{amat}{3}
        \vdots & \cdots & \cdots & x \\
        \vdots & \cdots & \cdots & x \\
        0 & 0 & \cdots & 0 \\
      \end{amat} \\[3em]

      \begin{amat}{3}
        \vdots & \cdots & \cdots & x \\
        \vdots & \cdots & \cdots & x \\
        0 & 0 & \cdots & 1 \\
      \end{amat}
    \end{cases}
  \end{equation*}

  In the second case, we can actually continue past the \nameref{thm:Echelon_Form} and get the original \nameref{def:Matrix} to yield $I$.
  This is shown in \Cref{ex:Elementary Row Operations to find Inverse}
\end{theorem}

\begin{example}[Lecture 14, Example 2]{Elementary Row Operations to find Inverse}
  Use \nameref{def:Elementary_Row_Op}s to find $A^{-1}$?
  \begin{equation*}
    A =
    \begin{pmatrix}
      1 & -2 & -3 \\
      -1 & 0 & 2 \\
      1 & 1 & -1
    \end{pmatrix}
  \end{equation*}
  \tcblower{}
  First, we attempt to put $A$ into \nameref{thm:Echelon_Form}.
  \begin{align*}
    A &=
    \begin{pmatrix}
      1 & -2 & -3 \\
      -1 & 0 & 2 \\
      1 & 1 & -1
    \end{pmatrix} &
                    I &=
                    \begin{pmatrix}
                      1 & 0 & 0 \\
                      0 & 1 & 0 \\
                      0 & 0 & 1
                    \end{pmatrix} \\
    &\grstep{r_{1}+r_{2}}
    \begin{pmatrix}
      1 & -2 & -3 \\
      0 & -2 & -1 \\
      1 & 1 & 1
    \end{pmatrix} &
                    E_{1} &=
                        \begin{pmatrix}
                          1 & 0 & 0 \\
                          1 & 1 & 0 \\
                          0 & 0 & 1
                        \end{pmatrix} \\
    &\grstep{-r_{1}+r_{3}}
    \begin{pmatrix}
      1 & -2 & -3 \\
      0 & -2 & -1 \\
      0 & 3 & 2
    \end{pmatrix} &
                    E_{2} E_{1} &=
                        \begin{pmatrix}
                          1 & 0 & 0 \\
                          1 & 1 & 0 \\
                          -1 & 0 & 1
                        \end{pmatrix} \\
    &\grstep{r_{3}+r_{2}}
    \begin{pmatrix}
      1 & -2 & -3 \\
      0 & 1 & 1 \\
      0 & 3 & 2
    \end{pmatrix} &
                    E_{3} E_{2} E_{1} &=
                        \begin{pmatrix}
                          1 & 0 & 0 \\
                          0 & 1 & 1 \\
                          -1 & 0 & 1
                        \end{pmatrix} \\
    &\grstep{-3r_{2}+r_{3}}
    \begin{pmatrix}
      1 & -2 & -3 \\
      0 & 1 & 1 \\
      0 & 0 & -1
    \end{pmatrix} &
                    E_{4} \cdots E_{1} &=
                        \begin{pmatrix}
                          1 & 0 & 0 \\
                          0 & 1 & 1 \\
                          -1 & -3 & -2
                        \end{pmatrix} \\
    &\grstep{-r_{3}}
    \begin{pmatrix}
      1 & -2 & -3 \\
      0 & 1 & 1 \\
      0 & 0 & 1
    \end{pmatrix} &
                    E_{5} \cdots E_{1} &=
                        \begin{pmatrix}
                          1 & 0 & 0 \\
                          0 & 1 & 1 \\
                          1 & 3 & 2
                        \end{pmatrix} \\
    \intertext{Now that we have a transformation of $A$ that is in \nameref{thm:Echelon_Form}, we can now further this and get $I$.
    We can do this because there is no row that has all zeros.}
    &\grstep{-r_{3}+r_{2}}
    \begin{pmatrix}
      1 & -2 & -3 \\
      0 & 1 & 0 \\
      0 & 0 & 1
    \end{pmatrix} &
                    E_{6} \cdots E_{1} &=
                        \begin{pmatrix}
                          1 & 0 & 0 \\
                          -1 & -2 & -1 \\
                          1 & 3 & 2
                        \end{pmatrix} \\
    &\grstep{3r_{3}+r_{1}}
    \begin{pmatrix}
      1 & -2 & 0 \\
      0 & 1 & 0 \\
      0 & 0 & 1
    \end{pmatrix} &
                    E_{7} \cdots E_{1} &=
                        \begin{pmatrix}
                          4 & 9 & 6 \\
                          -1 & -2 & -1 \\
                          1 & 3 & 2
                        \end{pmatrix} \\
    &\grstep{2r_{2}+r_{1}}
    \begin{pmatrix}
      1 & 0 & 0 \\
      0 & 1 & 0 \\
      0 & 0 & 1
    \end{pmatrix} &
                    E_{8} \cdots E_{1} &=
                        \begin{pmatrix}
                          2 & 5 & 4 \\
                          -1 & -2 & -1 \\
                          1 & 3 & 2
                        \end{pmatrix} \\
  \end{align*}

  Therefore, $E_{8} \cdots E_{1} = A^{-1}$, and is our solution.
  Remember:
  \begin{align*}
    BA &= I \\
    \shortintertext{Means that}
    B &= A^{-1} \\
    \shortintertext{Thus, if}
    E_{8} E_{7} E_{6} E_{5} E_{4} E_{3} E_{2} E_{1} A &= I \\
    A^{-1} &= E_{8} \cdots E_{1}
  \end{align*}
\end{example}

\Cref{ex:Elementary Row Operations to find Inverse} shows something very important.
\begin{remark*}
  Only matrices $A$ that have a finite number of \nameref{def:Elementary_Matrix} transformations have a possible \nameref{def:Inverse_Matrix}.

  Remember \Cref{thm:Inverse_Matrix_Uniqueness}.
  We are guaranteed to have a unique inverse matrix.
\end{remark*}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../Math_333-MatrixAlg_ComplexVars-Reference_Sheet"
%%% End:
