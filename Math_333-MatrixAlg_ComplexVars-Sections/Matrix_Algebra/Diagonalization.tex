\subsection{Diagonalization}\label{subsec:Diagonalization}
To start off with, we need some background knowledge on what we mean by \nameref{def:Diagonalization}.

\begin{definition}[Diagonal Matrix]\label{def:Diagonal_Matrix}
  A \emph{diagonal matrix} is a \nameref{def:Matrix} whose only non-zero elements are on the main diagonal of the matrix.

  In general, this is seen as:
  \begin{equation}\label{eq:Diagonal_Matrix}
    A =
    \begin{pmatrix}
      a_{1,1} & 0 & 0 & \cdots \\
      0 & a_{2,2} & 0 & \cdots \\
      \vdots & \ddots & \ddots & \vdots \\
      0 & \cdots & \cdots & a_{n, n}
    \end{pmatrix}
  \end{equation}
\end{definition}

\begin{definition}[Diagonalizable]\label{def:Diagonalizable}
  Let the \nameref{def:Matrix} $A_{n \by n}$.
  We say $A$ is \emph{diagonalizable} to a \nameref{def:Diagonal_Matrix} $D$ if there exists an invertible matrix $P$ such that \Cref{eq:Diagonalizable} holds true.

  \begin{equation}\label{eq:Diagonalizable}
    P^{-1} A P = D
  \end{equation}
\end{definition}

\begin{definition}[Diagonalization]\label{def:Diagonalization}
  Let the matrix $A_{n \by n}$ be \nameref{def:Diagonalizable} by an invertible \nameref{def:Matrix} $P$ to form a \nameref{def:Diagonal_Matrix} $D$.
  $P$ is called a matrix that implements the \emph{diagonalization} shown in \Cref{eq:Diagonalization}.

  \begin{equation}\label{eq:Diagonalization}
    AP = PD
  \end{equation}
\end{definition}

Now that we have the terms and definitions out of the way, we can see something interesting about \Cref{eq:Diagonalization}.
\begin{blackbox}
  Let $A_{2 \by 2}$, $P =
  \begin{pmatrix}
    p_{1} & p_{2}
  \end{pmatrix}
  $, and $D =
  \begin{pmatrix}
    d_{1} & 0 \\
    0 & d_{2}
  \end{pmatrix}$.

  This means that if we apply \Cref{eq:Diagonalization}:
  \begin{align*}
    AP &= PD \\
    A_{2 \by 2}
    \begin{pmatrix}
      p_{1} & p_{2}
    \end{pmatrix} &=
                    \begin{pmatrix}
                      p_{1} & p_{2}
                    \end{pmatrix}
                              \begin{pmatrix}
                                d_{1} & 0 \\
                                0 & d_{2} \\
                              \end{pmatrix} \\
    \begin{pmatrix}
      A p_{1} & A p_{2}
    \end{pmatrix} &=
                    \begin{pmatrix}
                      d_{1} p_{1} & d_{2} p_{2}
                    \end{pmatrix}
  \end{align*}

  This means that:
  \begin{align*}
    A p_{1} &= d_{1} p_{1} \\
    A p_{2} &= d_{2} p_{2}
  \end{align*}

  If we study this, we can see that $d_{1}$ and $d_{2}$ are \nameref{def:Eigenvalue}s of $A$ (Remember, $AX = \lambda X$).
  Therefore, $P$ is a \nameref{def:Matrix} that implements the \nameref{def:Diagonalization} using a matrix of corresponding \nameref{def:Eigenvector}s.
\end{blackbox}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../Math_333-MatrixAlg_ComplexVars-Reference_Sheet"
%%% End:
