\subsubsection{Discrete Random Variables}\label{subsubsec:Discrete_Random_Variables}
\begin{definition}[Discrete Random Variable]\label{def:Discrete_Random_Variable}
  A \emph{Discrete Random Variable} is one whose values are mapped from an \nameref{def:Event}'s outcome to the integer numbers ($\AllIntegers$).
  These \nameref{def:Random_Variable}s are drawn from outcomes that are finite (sides on a die) or countably infinite.

  The probability of a single value of the discrete random variable is denoted differently here than in the course material.
  The subscript refers to which discrete random variable we are working with (in this case $X$) and the variable in parentheses is the value we are calculating for (in this case $x \in X$).
  \begin{equation}\label{eq:Discrete_Random_Variable-Single_Value}
    p_{X}(x)
  \end{equation}

  The sum of all probabilities for values that the discrete random variable can take \textbf{must} sum to 1.
  \begin{equation}\label{eq:Discrete_Random_Variable-Sum_to_One}
    \sum\limits_{x \in X} p_{X}(x) = 1
  \end{equation}

  The mean or expected value of a discrete random variables is shown below:
  \begin{equation}\label{eq:Discrete_Random_Variable-Expected_Value}
    \begin{aligned}
      \mu = \sum\limits_{x \in X} x p_{X}(x) \\
      \ExpectedValue[X] = \sum\limits_{x \in X} x p_{X}(x) \\
    \end{aligned}
  \end{equation}

  The variance of a discrete random variable is how ``off'' a value from the random variable is from the mean/expected value.
  \begin{equation}\label{eq:Discrete_Random_Variable-Variance}
    \begin{aligned}
      \sigma^{2} &= \sum\limits_{x \in X} {\left( x - \mu \right)}^{2} p_{X}(x) \\
      \Variance[X] &= \sum\limits_{x \in X} {\bigl( x - \ExpectedValue[X] \bigr)}^{2} p_{X}(x) \\
    \end{aligned}
  \end{equation}

  The standard deviation is the square root of the variance.
  \begin{equation}\label{eq:Discrete_Random_Variable-Standard_Deviation}
    \begin{aligned}
      \sigma = \sqrt{\sigma^{2}} &= \sqrt{\sum\limits_{x \in X} {\left( x - \mu \right)}^{2} p_{X}(x)} \\
      \StdDev[X] = \sqrt{\Variance[X]} &= \sqrt{\sum\limits_{x \in X} {\bigl( x - \ExpectedValue[X] \bigr)}^{2} p_{X}(x)} \\
    \end{aligned}
  \end{equation}
\end{definition}

There are 5 different \nameref{def:Discrete_Random_Variable} distributions that we will be heavily utilizing in this course.

\paragraph{Uniform Random Variable}\label{par:Uniform_Random_Variable}
\begin{definition}[Uniform Random Variable]\label{def:Uniform_Random_Variable}
  The \emph{uniform random variable} is a \nameref{def:Discrete_Random_Variable} whose probabilities for each outcome is equal.

  For a \nameref{def:Discrete_Random_Variable} $X$, which has $\SetOrder{X}$ possible values,
  \begin{equation}\label{eq:Uniform_Random_Variable-Probability_Distribution}
    p_{X}(x) = \frac{1}{\SetOrder{X}}
  \end{equation}
\end{definition}

\begin{example}[Lecture 1]{Uniform Random Variable}
  For example, the roll of a die is typically modelled as a uniform random variable.
  Find the probability distribution function, the expected value, and the variance.
  \tcblower{}
  Let's assume this is a 6-sided die.
  And let's map each side's number to a value in the range of $X \in [1, 6]$.

  Using \Cref{eq:Uniform_Random_Variable-Probability_Distribution}, we can find the probability distribution easily.
  \begin{equation*}
    p_{X}(x) =
    \begin{cases}
      \frac{1}{6} & x = 1 \\
      \frac{1}{6} & x = 2 \\
      \frac{1}{6} & x = 3 \\
      \frac{1}{6} & x = 4 \\
      \frac{1}{6} & x = 5 \\
      \frac{1}{6} & x = 6 \\
    \end{cases}
  \end{equation*}

  Using \Cref{eq:Discrete_Random_Variable-Expected_Value}, we can find the the expected value/mean.
  \begin{equation*}
    \begin{aligned}
      \mu = \ExpectedValue[X] &= \sum\limits_{x=1}^{6}x p_{X}(x) \\
      &= \frac{1}{6} + \frac{2}{6} + \frac{3}{6} + \frac{4}{6} + \frac{5}{6} + \frac{6}{6} \\
      &= \frac{1+2+3+4+5+6}{6} \\
      &= \frac{21}{6} = 3.5
    \end{aligned}
  \end{equation*}

  Using \Cref{eq:Discrete_Random_Variable-Variance}, we can find the variance.
  \begin{equation*}
    \begin{aligned}
      \sigma^{2} = \Variance[X] &= \sum\limits_{x=1}^{6} {\bigl(x - \ExpectedValue[X] \bigr)}^{2} p_{X}(x) \\
      &= \sum\limits_{x=1}^{6} {(x-3.5)}^{2} \left( \frac{1}{6} \right) \\
      &= 2.91667
    \end{aligned}
  \end{equation*}

  Using \Cref{eq:Discrete_Random_Variable-Standard_Deviation}, we can find the standard deviation.
  \begin{equation*}
    \begin{aligned}
      \sigma = \StdDev[X]&= \sqrt{\sum\limits_{x=1}^{6} {\bigl(x - \ExpectedValue[X] \bigr)}^{2} p_{X}(x)} \\
      &= \sqrt{\sum\limits_{x=1}^{6} {(x-3.5)}^{2} \left( \frac{1}{6} \right)} \\
      &= \sqrt{2.91667} \\
      &= 1.70783
    \end{aligned}
  \end{equation*}
\end{example}

\paragraph{Bernoulli Random Variable}\label{par:Bernoulli_Random_Variable}
\begin{definition}[Bernoulli Random Variable]\label{def:Bernoulli_Random_Variable}
  The \emph{Bernoulli random variable} is one where \textbf{only one} test occurs, and there are only 2 outcomes.

  The probability of success is denoted
  \begin{equation}\label{eq:Bernoulli_Random_Variable-Success}
    p_{X}(\text{success}) = p
  \end{equation}

  The probability of failure is denoted
  \begin{equation}\label{eq:Bernoulli_Random_Variable-Failure}
    p_{X}(\text{failure}) = 1-p
  \end{equation}

  The mean/expected value is:
  \begin{equation}\label{eq:Bernoulli_Random_Variable-Expected_Value}
    \mu = \ExpectedValue[X] = p
  \end{equation}

  The variance is:
  \begin{equation}\label{eq:Bernoulli_Random_Variable-Variance}
    \sigma^{2} = \Variance[X] = (1-p) p
  \end{equation}
\end{definition}

\paragraph{Binomial Random Variable}\label{par:Binomial_Random_Variable}
\begin{definition}[Binomial Random Variable]\label{def:Binomial_Random_Variable}
  The \emph{binomial random variable} is one where $n$ trials are run with no stops for a success, where the \nameref{def:Random_Variable} in each run is a \nameref{def:Bernoulli_Random_Variable}.

  The probability of $k$ successes with $n$ trials is
  \begin{equation}\label{eq:Binomial_Random_Variable-Probability_Success}
    \binom{n}{k} p^{k} {(1-p)}^{n-k} = \frac{n!}{k! (n-k)!} {(1-p)}^{n-k}
  \end{equation}

  The mean/expected value after $n$ trials is
  \begin{equation}\label{eq:Bernoulli_Random_Variable-Expected_Value}
    \mu = \ExpectedValue[X] = np
  \end{equation}

  The variance after $n$ trials is
  \begin{equation}\label{eq:Bernoulli_Random_Variable-Variance}
    \sigma^{2} = \Variance[X] = np (1-p)
  \end{equation}
\end{definition}

\paragraph{Geometric Random Variable}\label{par:Geometric_Random_Variable}
\begin{definition}[Geometric Random Variable]\label{def:Geometric_Random_Variable}
  The \emph{geometric random variable} is one where $n$ trials are run, where the $n$th trial is a success, meaning there are $n-1$ previous failures.
  The \nameref{def:Random_Variable} in each run is a \nameref{def:Bernoulli_Random_Variable}.

  This means \textbf{each trial} has a probability of success of
  \begin{equation}\label{eq:Geometric_Random_Variable-Probability_Success}
    p_{X}(\text{success}) = p
  \end{equation}

  And \textbf{each trial} has a probability of failure of
  \begin{equation}\label{eq:Geometric_Random_Variable-Probability_Failure}
    p_{X}(\text{failure}) = 1-p
  \end{equation}

  The mean/expected value is
  \begin{equation}\label{eq:Geometric_Random_Variable-Expected_Value}
    \mu = \ExpectedValue[X] = \frac{1}{p}
  \end{equation}

  The variance is
  \begin{equation}\label{eq:Geometric_Random_Variable-Variance}
    \sigma^{2} = \Variance[X] = \frac{1-p}{p^{2}}
  \end{equation}
\end{definition}

\paragraph{Poisson Random Variable}\label{par:Poisson_Random_Variable}
\begin{definition}[Poisson Random Variable]\label{def:Poisson_Random_Variable}
  The \emph{Poisson random variable} is used to model the number of independent events that occur over a given period of time.

  The Poisson random variable has one parameter,
  \begin{equation}\label{eq:Poisson_Random_Variable-Lambda_Parameter}
    \lambda
  \end{equation}
  $\lambda$ is the average number of events per unit of time.

  The probability function for the value of $x \in X$ of this random variable is
  \begin{equation}\label{eq:Poisson_Random_Variable-Probability_Function}
    p_{X}(x) = e^{-\lambda} \left( \frac{\lambda^{x}}{k!} \right)
  \end{equation}

  The mean/expected value is
  \begin{equation}\label{eq:Poisson_Random_Variable-Expected_Value}
    \mu = \ExpectedValue[X] = \lambda
  \end{equation}

  The variance is
  \begin{equation}\label{eq:Poisson_Random_Variable-Variance}
    \sigma^{2} = \Variance[X] = \lambda
  \end{equation}
\end{definition}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../ETSN10-Network_Architecture_Performance-Reference_Sheet"
%%% End:
