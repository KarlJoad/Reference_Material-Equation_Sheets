\section{Statistics} \label{sec:Statistics}
In applying probability models to real situations, we perform experiments and collect data to answer questions such as:
	\begin{enumerate}[noitemsep, nolistsep]
		\item What are the values of the parameters of the distribution of a random variable of interest?
			\begin{itemize}[noitemsep, nolistsep]
				\item Mean or Expected value
				\item Variance
			\end{itemize}
		
		\item Is the data set consistent with some model?
			\begin{itemize}[noitemsep, nolistsep]
				\item Some assumed distribution, which must be true, otherwise the model is wrong.
			\end{itemize}
		
		\item Is the data set consistent with some parameter value of the assumed value?
	\end{enumerate}

	\begin{definition}[Statistic] \label{def:Statistic}
		A \emph{statistic} $W \left( X \right)$ is a function of the data from random variables $X_{1},X_{2},\ldots,X_{n}$.
	\end{definition}
	\begin{definition}[Unit Variance] \label{def:Unit Variance}
		The \emph{unit variance} means that the standard deviation, $\sigma$ of a sample, as well as the variance, $\sigma^{2}$ will tend towards 1 as the sample size increases to infinity.
	\end{definition}
	\subsection{Sums of Random Variables} \label{subsec:Sums of Random Variables}
		\begin{definition}[Sum of Random Variables] \label{def:Sum of Random Variables}
			The definition of a \emph{sum of random variables} is given in Equation~\eqref{eq:Sum of Random Variables} below.
			Where $X_{i}$ is a random variable,
			\begin{equation} \label{eq:Sum of Random Variables}
				S_{n} = \sum_{i=1}^{n} X_{i} = X_{1} + X_{2} + \ldots + X_{n}
			\end{equation}
		\end{definition}
	
	\subsubsection{Means and Variances of Sums of Random Variables} \label{subsubsec:Means and Variances of Sums of Random Variables}
		\begin{definition}[Mean of Sums of Random Variables] \label{def:Mean of Sums of Random Variables}
			The \emph{mean of sums of random variables} is the same as the \emph{expected value of sums of random variables}.
			\begin{equation}
				\ExpectedValue \left[ S_{n} \right] = \sum_{i=1}^{n} \ExpectedValue \left[ X_{i} \right]
			\end{equation}
			\begin{remark}
				All the properties of \nameref{subsubsec:Properties of Discrete Expected Value} and/or \nameref{subsubsec:Properties of Continuous Expected Value} hold true here as well..
			\end{remark}
		\end{definition}
		\begin{definition}[Variance of Sums of Random Variables] \label{def:Variance of Sums of Random Variables}
			The defintion of the \emph{variance of sums of random variables} is the same as we have been using them previously, \nameref{subsec:Variance of Single Discrete} and \nameref{subsec:Variance of Single Continuous}.
			\begin{equation} \label{eq:Variance of Sums of Random Variables}
				\Variance \left[ S_{n} \right] = \Variance \left[ \sum_{i=1}^{n} X_{i} \right] = \sum_{i=1}^{n} \Variance \left[ X_{i} \right] + \sum_{j=1}^{n} \sum_{\substack{k=1 \\ j \neq k}}^{n} \Covariance \left[ X_{j}, X_{k} \right]
			\end{equation}
			\begin{remark} \label{rmk:Variance of Sums of Independent Random Variables}
				If $X_{1}, X_{2}, \ldots , X_{n}$ are independent, then:
				\begin{equation} \label{eq:Variance of Sums of Independent Random Variables}
					\Variance \left[ \sum_{i=1}^{n} X_{i} \right] = \sum_{i=1}^{n} \Variance \left[ X_{i} \right]
				\end{equation}
			\end{remark}
		\end{definition}
		\begin{definition}[Independent and Identically Distributed] \label{def:Independent and Identically Distributed}
			We say that $X_{1},X_{2},\ldots,X_{n}$ are \emph{Independent and Identically Distributed (iid)} random variables if $X_{i}$ are drawn independently from the same population/probability distribution.
			\begin{subequations}
				\begin{equation} \label{eq:Mean of Independent and Identically Distributed}
					\sum_{i=1}^{n} \ExpectedValue \left[ X_{i} \right] = n \mu
				\end{equation}
				\begin{equation} \label{eq:Variance of Independent and Identically Distributed}
					\Variance \left[ S_{n} \right] = n \sigma^{2}
				\end{equation}
			\end{subequations}
			\begin{itemize}[noitemsep, nolistsep]
				\item $\mu$ is the mean of a random variable $X_{i}$
				\item $\sigma^{2}$ is the variance of a random variable $X_{i}$.
			\end{itemize}
		\end{definition}
	
	\subsection{Sample Mean} \label{subsec:Sample Mean}
		\begin{definition}[Sample Mean] \label{def:Sample Mean}
			The \emph{sample mean} of a sequence is denoted as,
			\begin{equation} \label{eq:Sample Mean}
				\bar{X} = M_{n} = \frac{\sum_{i=1}^{n} X_{i}}{n}
			\end{equation}
		\end{definition}
		\begin{definition}[Expected Value of Sample Mean] \label{def:Expected Value of Sample Mean}
			The \emph{expected value of the sample mean} is defined as:
			\begin{equation} \label{eq:Expected Value of Sample Mean}
				\ExpectedValue \left[ \bar{X} \right]
				= \ExpectedValue \left[ M_{n} \right]
				= \frac{\ExpectedValue \left[ S_{n} \right]}{n}
				= \frac{n \mu}{n}
				= \mu
			\end{equation}
			\begin{remark}
				The sample mean $M_{n}$ is an \emph{\nameref{def:Unbiased Estimator}} of population mean $\mu$.
			\end{remark}
		\end{definition}
		\begin{definition}[Variance of Sample Mean] \label{def:Variance of Sample Mean}
			The \emph{variance of the sample mean} is denoted as:
			\begin{equation} \label{eq:Variance of Sample Mean}
				\Variance \left[ \bar{X} \right]
				= \Variance \left[ M_{n} \right]
				= \Variance \left[ \frac{S_{n}}{n} \right]
				= \frac{1}{n^{2}} \Variance \left[ S_{n} \right]
				= \frac{\sigma^{2}}{n}
			\end{equation}
			\begin{remark}
				The larger $n$ gets, the smaller $\Variance \left[ M_{n} \right]$ gets, and the closer $M_{n}$ gets to $\mu$.
			\end{remark}
		\end{definition}
		\begin{definition}[Unbiased Estimator] \label{def:Unbiased Estimator}
			In general we say that a \nameref{def:Statistic} $W \left( X \right)$ (a function of data $X_{1},X_{2},\ldots,X_{n}$) is an \emph{unbiased estimator} of a parameter $\theta$ if $\ExpectedValue \left[ W \left( X \right) \right] = \theta$.
			\begin{remark}[What makes a good estimator of any parameter, $\theta$?]
				A \emph{good estimator} of any parameter, $\theta$, should:
				\begin{itemize}[noitemsep, nolistsep]
					\item Give the correct value of $\theta$
					\item Not vary too much around $\theta$
				\end{itemize}
			\end{remark}
		\end{definition}
	
	Also, we can use the \nameref{eq:Chebychev Inequality} to approximate many values. In this case, we change the Chebychev Inequality from Equation~\eqref{eq:Chebychev Inequality} to Equation~\eqref{eq:Statistics Chebychev Inequality} like so:
		\begin{equation} \label{eq:Statistics Chebychev Inequality}
			P \left[ \lvert M_{n} - \ExpectedValue \left[ M_{n} \right] \rvert \geq \varepsilon \right] \leq \frac{\Variance \left[ M_{n} \right]}{\varepsilon^{2}}
		\end{equation}
		
	\subsection{Important Probability and Statistics Theorems} \label{subsec:Important Probability and Statistics Theorems}
		There are 3 very import theorems that are used quite frequently in both \nameref{sec:Probability Theory} and \nameref{sec:Statistics}.
		\begin{enumerate}[noitemsep, nolistsep]
			\item 
			\item 
			\item 
		\end{enumerate}
		\begin{theorem}[Weak Law of Large Numbers] \label{thm:Weak Law of Large Numbers}
			Let $X_{1},X_{2},\ldots,X_{n}$ be a sequence of \nameref{def:Independent and Identically Distributed} random variables form a population with mean $\ExpectedValue \left[ X \right] = \mu$, then for $\varepsilon > 0$,
			\begin{equation} \label{eq:Weak Law of Large Numbers}
				\lim\limits_{n \rightarrow \infty} P \left[ \lvert M_{n} - \mu \rvert < \varepsilon \right] = 1
			\end{equation}
			\begin{remark*}
				In words this means, for large enough fixed values of $n$, $M_{n}$ is close to $\mu$ with high probability.
			\end{remark*}
		\end{theorem}
		\begin{theorem}[Strong Law of Large Numbers] \label{thm:Strong Law of Large Numbers}
			Let $X_{1},X_{2},\ldots,X_{n}$ be a sequence of \nameref{def:Independent and Identically Distributed} random variables form a population with mean $\ExpectedValue \left[ X \right] = \mu$ and finite variance, then
			\begin{equation} \label{eq:Strong Law of Large Numbers}
				P \left[ \lim\limits_{n \rightarrow \infty} M_{n} = \mu \right] = 1
			\end{equation}
			\begin{remark*}
				With probability 1, every sequence of sample mean calculations will eventually approach and stay close to the population mean.
			\end{remark*}
		\end{theorem}
		\begin{theorem}[Central Limit Theorem] \label{thm:Central Limit Theorem}
			Let $X_{1},X_{2},\ldots,X_{n}$ be a sequence of \nameref{def:Independent and Identically Distributed} random variables form a population with mean $\ExpectedValue \left[ X \right] = \mu < \infty$ and finite variance $\sigma^{2}$ and let
			\begin{equation*}
				Z_{n} = \frac{S_{n} - n\mu}{\sigma \sqrt{n}} = \frac{\bar{X} - \mu}{\frac{\sigma}{\sqrt{n}}}
			\end{equation*}
			then,
			\begin{equation} \label{eq:Central Limit Theorem}
				\lim\limits_{n \rightarrow \infty} P \left[ Z_{n} \leq z \right] = \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{z} e^{-\frac{x^{2}}{2}} dx
			\end{equation}
			\begin{remark*}
				This means that over time, as you gain more and more sample means, they will start to resemble the \nameref{def:Gaussian Random Variable}, or the Normal Random Variable.
			\end{remark*}
		\end{theorem}