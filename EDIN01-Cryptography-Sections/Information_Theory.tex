\section{Information Theory}\label{sec:Information_Theory}
Information theory is heavily influenced by probability and its theories.
For \textbf{much} greater detail on some of the concepts presented here, refer to the \href{file:./Math_374-Reference_Sheet.pdf}{Math 374 - Probability and Statistics} document.

\begin{definition}[Random Experiment]\label{def:Random_Experiment}
  A \emph{random experiment} is an experiment whose outcome varies in an unpredictable fashion when performed under the same conditions.
\end{definition}

\subsection{Sample Space}\label{subsec:Sample_Space}
\begin{definition}[Sample Space]\label{def:Sample_Space}
  The \emph{sample space} is the set of \textbf{all} possible outcomes, the \nameref{def:Elementary_Event}s, denoted
  \begin{equation}\label{eq:Sample_Space}
    \Omega = \lbrace \omega_{1}, \omega_{2}, \ldots, \omega_{n} \rbrace
  \end{equation}
\end{definition}

\begin{definition}[Elementary Event]\label{def:Elementary_Event}
  The possible outcomes in a \nameref{def:Sample_Space} are called \emph{elementary event}s.
  In \Cref{eq:Sample_Space}, they are denoted
  \begin{equation}\label{eq:Elementary_Event}
    \omega_{i}
  \end{equation}
\end{definition}

\begin{definition}[Event]\label{def:Event}
  An \emph{event} is any subset of $\Omega$.
  \begin{equation}\label{eq:Event}
    E \subset \Omega
  \end{equation}
\end{definition}

\begin{definition}[Probability]\label{def:Probability}
  The \emph{probability} of an \nameref{def:Event} $E$ is given by
  \begin{equation}\label{eq:Probability}
    \Prob(E) = \sum\limits_{\omega \in E} \Prob(\omega)
  \end{equation}
\end{definition}

\begin{definition}[Random Variable]\label{def:Random_Variable}
  A \emph{random variable} $X$ is a function that assigns a real number $X(\zeta)$ to each outcome $\zeta$ in the \nameref{def:Sample_Space} of the \nameref{def:Random_Experiment}.
\end{definition}

\subsection{Discrete Random Variables}\label{subsec:Discrete_Random_Variables}
\begin{definition}[Discrete Random Variable]\label{def:Discrete_Random_Variable}
  A \emph{discrete random variable} is a \nameref{def:Random_Variable} that assumes values from a finite set, $\mathcal{X}$
  It is a mapping
  \begin{equation}\label{eq:Discrete_Random_Variable}
    X(\omega) : \Omega \mapsto \mathcal{X}
  \end{equation}
\end{definition}

\begin{definition}[Probability Distribution]\label{def:Probability_Distribution}
  A \nameref{def:Discrete_Random_Variable} has a \emph{probability distribution} $P(X=x)$
  \begin{equation}\label{eq:Probability_Distribution}
    \Prob(X=x) = \sum\limits_{\omega : X(\omega) = x} \Prob(x)
  \end{equation}

  If $E \subset \mathcal{X}$, then $X \in E$ is an \nameref{def:Event} and
  \begin{equation}\label{eq:7}
    \Prob(X \in E) = \sum\limits_{x \in E} \Prob(x)
  \end{equation}
\end{definition}

\subsubsection{Independent Discrete Random Variables}\label{subsubsec:Independent_Discrete_Random_Variables}
\subsubsection{Conditional Probability of  Discrete Random Variables}\label{subsubsec:Conditional_Probability_Discrete_Random_Variables}

\subsection{Entropy}\label{subsec:Entropy}
\subsubsection{Properties of \nameref*{subsec:Entropy}}\label{subsubsec:Entropy_Properties}

\subsubsection{Conditional Entropy}\label{subsubsec:Conditional_Entropy}
\paragraph{Properties of \nameref*{subsubsec:Conditional_Entropy}}\label{par:Conditional_Entropy_Properties}

\subsubsection{Relative Entropy}\label{subsubsec:Relative_Entropy}

\subsection{Mutual Information}\label{subsec:Mutual_Information}
\subsubsection{Properties of \nameref*{subsec:Mutual_Information}}\label{subsubsec:Mutual_Information_Properties}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../EDIN01-Cryptography-Reference_Sheet"
%%% End:
